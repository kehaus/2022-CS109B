{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs109b_lab9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Introduction to Data Science\n",
        "\n",
        "## Lab 9: NLP, RNNs, LSTMs, ELMo \n",
        "\n",
        "**Harvard University**<br/>\n",
        "**Spring 2022**<br/>\n",
        "**Instructors**: Mark Glickman & Pavlos Protopapas<br/>\n",
        "**Authors**: Shivas Jayaram\n",
        "<br/>"
      ],
      "metadata": {
        "id": "RTwjswBgwh9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Objectives\n",
        "\n",
        "By the end of this Lab, you should understand how to:\n",
        "* Perform **preprocessing** operation on text\n",
        "* **Tokenization** for Deep Learning models\n",
        "* Build and compare various **RNN** Architectures\n",
        "* Build **LSTMs** with Residual connections\n",
        "* **ELMo** from sctrach using Highway Networks\n",
        "* Setting up **TensorBoard** in Colab\n",
        "\n",
        "---\n",
        "You will also learn the following:\n",
        "<p><strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : \n",
        "<ul>\n",
        "<li>üîë TF Data</li>\n",
        "<li>üîë Model using functional API</li>\n",
        "<li>üîë Custom Layer</li>\n",
        "</ul>\n",
        "</font></strong></p>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qjXBHdlVxdwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"contents\"></a>\n",
        "\n",
        "## Notebook Contents\n",
        "\n",
        "- [**Preprocessing Text Data Recap**](#prep)\n",
        "    - [Review NLP Terminologies](#prep)\n",
        "    - [Text processing using NLTK](#prep) \n",
        "    - [Stop words, Word Stemmer, Lemmatization](#prep)\n",
        "    - [Tokenization for Deep Learning](#prep)\n",
        "- [**Recurrent Neural Networks**](#rnn)   \n",
        "    - [Creating various RNN model architectures](#rnn)\n",
        "- [**LSTMs**](#lstms) \n",
        "  - [Creating LSTMs with Residual connections](#lstms)\n",
        "- [**ELMo and Highway Networks**](#elmo)      \n",
        "- [**Using TensorBaord in Colab**](#tensorboard) "
      ],
      "metadata": {
        "id": "Zor_Wr8Vxkfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup Notebook**"
      ],
      "metadata": {
        "id": "RAM_-TzxyEm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "kjgnOSl9yP_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MBh7Da09vHt9"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import SpaceTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import manifold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download nltk's punkt sentence tokenizer\n",
        "nltk.download('punkt')\n",
        "# download nltk's stop words\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "D9LeKyyI0mby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fcc567-11f9-4362-b5ec-b43f22ebddfe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Setup**"
      ],
      "metadata": {
        "id": "3WYZljtMyXnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a good practice to verify what version of TensorFlow & Keras you are using. Also verify if GPU is enabled and what GPU you have. Run the following cells to check the version of TensorFlow\n",
        "\n",
        "References:\n",
        "- [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "- [Data Performance](https://www.tensorflow.org/guide/data_performance)"
      ],
      "metadata": {
        "id": "17RkYjSxyaae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable/Disable Eager Execution\n",
        "# Reference: https://www.tensorflow.org/guide/eager\n",
        "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
        "# without building graphs\n",
        "\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"keras version\", tf.keras.__version__)\n",
        "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
        "\n",
        "# Get the number of replicas \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "devices = tf.config.experimental.get_visible_devices()\n",
        "print(\"Devices:\", devices)\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))\n",
        "\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
        "\n",
        "# Better performance with the tf.data API\n",
        "# Reference: https://www.tensorflow.org/guide/data_performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "6PBpsXEayaxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f00ebb3-e158-4a84-c9fc-4f48013ec2d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version 2.8.0\n",
            "keras version 2.8.0\n",
            "Eager Execution Enabled: True\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of replicas: 1\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check what GPU you have"
      ],
      "metadata": {
        "id": "JSTTuvGGyfQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "aTi15newyhfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b183429-848f-4832-b664-5cc09600caa4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 11 20:19:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    58W / 149W |    147MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utils\n",
        "def display_solution(activity):\n",
        "  response = requests.get(activity)\n",
        "  print(response.text)  "
      ],
      "metadata": {
        "id": "85H8bRmxDzLC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing Text Data** <div id='prep'>"
      ],
      "metadata": {
        "id": "SMO036PRhlXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Review**"
      ],
      "metadata": {
        "id": "5s7W0TCCjot5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Definitions:**\n",
        "- Natural Language Processing (NLP): The use of computers to process linguistic information into structured data and extract useful insights\n",
        "- Document: A single unit of observation used in NLP, which could be as short as a word or as long as a book\n",
        "- Corpus: A collection of documents from a shared context that are processed and analyzed using NLP\n",
        "\n",
        "**Conceptual:**\n",
        "- Text is structured data, but lacks the simple structure needed for quantitative analysis and ML\n",
        "- Extensive preprocessing and parsing is needed to convert plain text into structured data\n",
        "- How to parse a given document depends upon the specific application and the corpus being used\n",
        "- Once parsed, documents can be analyzed like other quantitative datasets \n",
        "\n",
        "\n",
        "**Common NLP Tools:**\n",
        "- [<font>Natural Language Toolkit</font>](https://www.nltk.org)\n",
        "- [scikit-learn](https://scikit-learn.org)\n",
        "- [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)\n",
        "- [Gensim](https://radimrehurek.com/gensim/)\n",
        "- [spaCy](https://spacy.io/)\n",
        "- [AllenNLP](https://allennlp.org/)\n",
        "- [<font>Transformers</font>](https://huggingface.co/transformers/index.html)\n",
        "\n",
        "**Basic Data Pipeline for NLP:**\n",
        "- <font>Data ingestion from files, scraping, APIs</font>\n",
        "- <font>Converting to lowercase</font>\n",
        "- Treating each punctuation mark as a token (e.g., , . ! ?)\n",
        "- Removing punctuation altogether\n",
        "- <font>Removing stop words (very common words like the, if, to ...)</font>\n",
        "- Word stemming (Stemming removes or stems the last few characters of a word)\n",
        "- Lemmatization (Lemmatization considers the context and converts the word to its meaningful base form)\n",
        "- <font>Parsing text using regular expressions</font>\n",
        "- <font>Tokenizing / Text Vectorization</font>\n",
        "- Creating n-grams\n",
        "- Creating TF-IDF vectors\n",
        "- <font>Creating word embeddings</font>\n",
        "\n",
        "**Modeling Strategies**\n",
        "- <strong>Creating ‚Äúbag of words‚Äù models</strong>\n",
        "- <strong>Creating ‚Äúsequence 2 sequence‚Äù models</strong>"
      ],
      "metadata": {
        "id": "ANn5RwqBjtQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocessing using NLTK**"
      ],
      "metadata": {
        "id": "MUyXFonByrNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider this input text"
      ],
      "metadata": {
        "id": "bwblOF6L0vlP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AMXlvRWmhSZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bb8311-3864-4a66-b7de-f206bfa50ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. \n",
            "Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, \n",
            "data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures \n",
            "such as CNNs, RNNs, transformers, language models, autoencoders, and generative models as well as basic \n",
            "Bayesian methods, and unsupervised learning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = \"\"\"Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science. \n",
        "Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, \n",
        "data visualization, statistical modeling, and prediction. Topics include big data, multiple deep learning architectures \n",
        "such as CNNs, RNNs, transformers, language models, autoencoders, and generative models as well as basic \n",
        "Bayesian methods, and unsupervised learning.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Input Text:\",input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we break this paragraph of text into:\n",
        "- Sentences\n",
        "- Words"
      ],
      "metadata": {
        "id": "Njzgubdg09D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sentences\n",
        "sentences = sent_tokenize(input_text)\n",
        "print(\"Sentences:\")\n",
        "for index, sentence in enumerate(sentences):\n",
        "  print(index,sentence)\n",
        "\n",
        "\n",
        "# Number of sentences\n",
        "print(\"\\n Number of Sentences:\", len(sentences))"
      ],
      "metadata": {
        "id": "4FTm7xBYmk4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7d99fe-87a6-44b9-b675-5298fb7d9b6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences:\n",
            "0 Advanced Topics in Data Science (CS109b) is the second half of a one-year introduction to data science.\n",
            "1 Building upon the material in Introduction to Data Science, the course introduces advanced methods for data wrangling, \n",
            "data visualization, statistical modeling, and prediction.\n",
            "2 Topics include big data, multiple deep learning architectures \n",
            "such as CNNs, RNNs, transformers, language models, autoencoders, and generative models as well as basic \n",
            "Bayesian methods, and unsupervised learning.\n",
            "\n",
            " Number of Sentences: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get words\n",
        "words = word_tokenize(input_text)\n",
        "print(\"\\nWords:\")\n",
        "print(words)\n",
        "\n",
        "# Number of words\n",
        "print(\"\\n Number of Words:\", len(words))"
      ],
      "metadata": {
        "id": "-Rih3h0j1XHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4fc85f-2ac6-49e9-9dc2-ef9ca0eb15ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Words:\n",
            "['Advanced', 'Topics', 'in', 'Data', 'Science', '(', 'CS109b', ')', 'is', 'the', 'second', 'half', 'of', 'a', 'one-year', 'introduction', 'to', 'data', 'science', '.', 'Building', 'upon', 'the', 'material', 'in', 'Introduction', 'to', 'Data', 'Science', ',', 'the', 'course', 'introduces', 'advanced', 'methods', 'for', 'data', 'wrangling', ',', 'data', 'visualization', ',', 'statistical', 'modeling', ',', 'and', 'prediction', '.', 'Topics', 'include', 'big', 'data', ',', 'multiple', 'deep', 'learning', 'architectures', 'such', 'as', 'CNNs', ',', 'RNNs', ',', 'transformers', ',', 'language', 'models', ',', 'autoencoders', ',', 'and', 'generative', 'models', 'as', 'well', 'as', 'basic', 'Bayesian', 'methods', ',', 'and', 'unsupervised', 'learning', '.']\n",
            "\n",
            " Number of Words: 84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will use a Regular expression tokenizer from the NLTK library to remove any punctuation and get only words as tokens"
      ],
      "metadata": {
        "id": "Y9DbYZvr2JvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Word tokenizer from NLTK\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Word Tokenize text\n",
        "words = tokenizer.tokenize(input_text)\n",
        "print(\"Words:\")\n",
        "print(words)\n",
        "\n",
        "# Number of words\n",
        "print(\"\\n Number of Words:\", len(words))"
      ],
      "metadata": {
        "id": "1iM9hF-mz_LH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c569e278-23cc-4f33-bac1-5fccd007fda4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words:\n",
            "['Advanced', 'Topics', 'in', 'Data', 'Science', 'CS109b', 'is', 'the', 'second', 'half', 'of', 'a', 'one', 'year', 'introduction', 'to', 'data', 'science', 'Building', 'upon', 'the', 'material', 'in', 'Introduction', 'to', 'Data', 'Science', 'the', 'course', 'introduces', 'advanced', 'methods', 'for', 'data', 'wrangling', 'data', 'visualization', 'statistical', 'modeling', 'and', 'prediction', 'Topics', 'include', 'big', 'data', 'multiple', 'deep', 'learning', 'architectures', 'such', 'as', 'CNNs', 'RNNs', 'transformers', 'language', 'models', 'autoencoders', 'and', 'generative', 'models', 'as', 'well', 'as', 'basic', 'Bayesian', 'methods', 'and', 'unsupervised', 'learning']\n",
            "\n",
            " Number of Words: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are the number of tokens in this method less than before?"
      ],
      "metadata": {
        "id": "hacwwkna2iU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stop words\n",
        "\n",
        "Words occuring frequently e.g: is, the etc"
      ],
      "metadata": {
        "id": "Xe4dAloaCjgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "id": "HHShfxpUUcfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a71f525-c8ee-4d68-ca1d-aded23df642a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Advanced',\n",
              " 'Topics',\n",
              " 'in',\n",
              " 'Data',\n",
              " 'Science',\n",
              " 'CS109b',\n",
              " 'is',\n",
              " 'the',\n",
              " 'second',\n",
              " 'half',\n",
              " 'of',\n",
              " 'a',\n",
              " 'one',\n",
              " 'year',\n",
              " 'introduction',\n",
              " 'to',\n",
              " 'data',\n",
              " 'science',\n",
              " 'Building',\n",
              " 'upon',\n",
              " 'the',\n",
              " 'material',\n",
              " 'in',\n",
              " 'Introduction',\n",
              " 'to',\n",
              " 'Data',\n",
              " 'Science',\n",
              " 'the',\n",
              " 'course',\n",
              " 'introduces',\n",
              " 'advanced',\n",
              " 'methods',\n",
              " 'for',\n",
              " 'data',\n",
              " 'wrangling',\n",
              " 'data',\n",
              " 'visualization',\n",
              " 'statistical',\n",
              " 'modeling',\n",
              " 'and',\n",
              " 'prediction',\n",
              " 'Topics',\n",
              " 'include',\n",
              " 'big',\n",
              " 'data',\n",
              " 'multiple',\n",
              " 'deep',\n",
              " 'learning',\n",
              " 'architectures',\n",
              " 'such',\n",
              " 'as',\n",
              " 'CNNs',\n",
              " 'RNNs',\n",
              " 'transformers',\n",
              " 'language',\n",
              " 'models',\n",
              " 'autoencoders',\n",
              " 'and',\n",
              " 'generative',\n",
              " 'models',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'basic',\n",
              " 'Bayesian',\n",
              " 'methods',\n",
              " 'and',\n",
              " 'unsupervised',\n",
              " 'learning']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stops = set(stopwords.words(\"english\")) #stops\n",
        "\n",
        "print(\"Stop words from NLTK:\\n\",stops) #Already defined in NLTK\n",
        "print('%d stop words' % len(stops))\n",
        "stops = stops.union(['I','using'])\n",
        "\n",
        "# Find unique words that are not in the stop words\n",
        "words = set([w for w in words if not w in stops])\n",
        "print(\"Processed words:\\n\",words)\n",
        "print('%d words' % len(words))"
      ],
      "metadata": {
        "id": "gzl7kL98Cj9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3ac222-12d7-416f-a2f0-1a8b38d6c6b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words from NLTK:\n",
            " {'the', 'ma', 'ours', 'hers', 'mightn', \"you'd\", \"mightn't\", 'wouldn', 'has', 'him', 'had', 'you', 't', 'both', 'here', \"wasn't\", 'its', 'have', 'all', 'about', 'm', \"that'll\", 'being', 'be', 'we', 'why', 'off', 'herself', 'and', 'them', 'further', 'there', 'won', 'nor', 'only', 'they', \"aren't\", 'through', 'until', 'ourselves', 'but', 'once', 'this', 'or', 'no', 'if', \"doesn't\", 'who', 'y', \"you're\", 'isn', \"mustn't\", 'doesn', \"didn't\", 'yours', 'so', 'me', 'his', 'd', 'she', 'now', 'an', 'how', 'too', 'themselves', 'mustn', 'again', 'it', 'same', 'down', 'whom', \"hasn't\", 'hadn', 'for', 'at', 're', 'each', 'been', \"hadn't\", 'shouldn', 'haven', 'where', \"weren't\", \"haven't\", 'own', 'can', 'should', 'any', \"shouldn't\", 'to', 'will', 'very', 'is', 'from', 'were', 'a', 'above', 'your', 'than', 'over', \"couldn't\", 'i', 'wasn', 'was', 'am', \"wouldn't\", 'myself', \"should've\", \"you've\", 'on', 'their', 'some', 'what', 'does', 'do', 'her', 'are', \"you'll\", 'as', 'needn', 'he', 'that', 'below', 'those', 'hasn', 'doing', 'll', 'weren', 'yourself', 'himself', 'which', 'few', \"needn't\", 'up', 'itself', 'theirs', 'after', 'by', 'these', 'o', 'under', 'ain', \"don't\", \"isn't\", 'not', 'don', 'because', 'out', 'with', 'of', 's', 'my', 'when', 'couldn', \"it's\", \"shan't\", 'into', 'in', 'aren', 've', 'our', 'did', 'yourselves', 'against', 'more', 'other', 'shan', 'then', 'just', 'having', 'most', \"won't\", 'didn', 'such', 'between', 'during', 'before', \"she's\", 'while'}\n",
            "179 stop words\n",
            "Processed words:\n",
            " {'visualization', 'one', 'introduction', 'Introduction', 'include', 'unsupervised', 'material', 'transformers', 'generative', 'Advanced', 'CNNs', 'wrangling', 'deep', 'introduces', 'prediction', 'science', 'statistical', 'advanced', 'big', 'CS109b', 'autoencoders', 'Science', 'Bayesian', 'language', 'course', 'basic', 'well', 'half', 'Building', 'methods', 'upon', 'Data', 'data', 'RNNs', 'year', 'second', 'models', 'Topics', 'learning', 'multiple', 'architectures', 'modeling'}\n",
            "42 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After removing stop words we hav even smaller vocabulary"
      ],
      "metadata": {
        "id": "Caseopvu3POW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Stemmer\n",
        "\n",
        "Another useful technique is word stemming, which is the process of transforming a word into its root form that allows us to map related words to the same stem. Stemming removes word endings to group together words with the same stem. For example, the words \"finding\" and \"finds\" would all be reduced to \"find\"."
      ],
      "metadata": {
        "id": "kl5kYMQZCy-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "     return [porter.stem(word) for word in text.split()]\n",
        "tokenizer_porter('runners like running and thus they run finding find finds finder')"
      ],
      "metadata": {
        "id": "JCjP-naSCzds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c218834f-b248-4d54-842d-ff237220f999"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner',\n",
              " 'like',\n",
              " 'run',\n",
              " 'and',\n",
              " 'thu',\n",
              " 'they',\n",
              " 'run',\n",
              " 'find',\n",
              " 'find',\n",
              " 'find',\n",
              " 'finder']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Lemmatization\n",
        "While stemming just uses the character strings to find the common base, lemmatization looks up the part of speech of a word and converts it to a noun form. "
      ],
      "metadata": {
        "id": "2hokVV0WDIFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def tokenizer_lemmatize(text):\n",
        "     return [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "tokenizer_lemmatize('runners like running and thus they run runs finding find finds finder')"
      ],
      "metadata": {
        "id": "OKiCNwj-DIoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ced16b1-097a-49b2-cf43-26d0cee4d88e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner',\n",
              " 'like',\n",
              " 'running',\n",
              " 'and',\n",
              " 'thus',\n",
              " 'they',\n",
              " 'run',\n",
              " 'run',\n",
              " 'finding',\n",
              " 'find',\n",
              " 'find',\n",
              " 'finder']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tokenization for Deep Learning**"
      ],
      "metadata": {
        "id": "UmFiLdHJ3fFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets review the text preprocessing steps and how we can build our data pipelines for Deep Learning models\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/public_colab_images/nlp/tokenization_for_dl.png\" />\n"
      ],
      "metadata": {
        "id": "KB2Jse_CzTpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **tf.keras: Tokenizer**"
      ],
      "metadata": {
        "id": "gnbJmOn21O8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None,\n",
        "                                                filters='\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                                lower=True,\n",
        "                                                oov_token=\"UNK\",\n",
        "                                                split=' ',)\n",
        "\n",
        "# Fit on text to generate token index and vocabulary\n",
        "tokenizer.fit_on_texts([input_text])\n",
        "\n",
        "# Tokenize\n",
        "tokens = tokenizer.texts_to_sequences([input_text])\n",
        "\n",
        "print(tokenizer.word_counts)\n",
        "word_index = tokenizer.word_index\n",
        "index_word = tokenizer.index_word\n",
        "print(\"word_index\",word_index)\n",
        "vocabulary_size = len(word_index.keys())\n",
        "print(\"Vocabulary Size:\",vocabulary_size)\n",
        "\n",
        "\n",
        "print(\"\\nExample:\",tokenizer.texts_to_sequences([\"data science is awesome\"]))\n",
        "print(\"\\nExample:\",tokenizer.texts_to_sequences([\"I like ice cream\"]))"
      ],
      "metadata": {
        "id": "TavdaRTenhT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430b63cf-4aad-42aa-aacf-ea6e3a06a684"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('advanced', 2), ('topics', 2), ('in', 2), ('data', 6), ('science', 3), ('cs109b', 1), ('is', 1), ('the', 3), ('second', 1), ('half', 1), ('of', 1), ('a', 1), ('one', 1), ('year', 1), ('introduction', 2), ('to', 2), ('building', 1), ('upon', 1), ('material', 1), ('course', 1), ('introduces', 1), ('methods', 2), ('for', 1), ('wrangling', 1), ('visualization', 1), ('statistical', 1), ('modeling', 1), ('and', 3), ('prediction', 1), ('include', 1), ('big', 1), ('multiple', 1), ('deep', 1), ('learning', 2), ('architectures', 1), ('such', 1), ('as', 3), ('cnns', 1), ('rnns', 1), ('transformers', 1), ('language', 1), ('models', 2), ('autoencoders', 1), ('generative', 1), ('well', 1), ('basic', 1), ('bayesian', 1), ('unsupervised', 1)])\n",
            "word_index {'UNK': 1, 'data': 2, 'science': 3, 'the': 4, 'and': 5, 'as': 6, 'advanced': 7, 'topics': 8, 'in': 9, 'introduction': 10, 'to': 11, 'methods': 12, 'learning': 13, 'models': 14, 'cs109b': 15, 'is': 16, 'second': 17, 'half': 18, 'of': 19, 'a': 20, 'one': 21, 'year': 22, 'building': 23, 'upon': 24, 'material': 25, 'course': 26, 'introduces': 27, 'for': 28, 'wrangling': 29, 'visualization': 30, 'statistical': 31, 'modeling': 32, 'prediction': 33, 'include': 34, 'big': 35, 'multiple': 36, 'deep': 37, 'architectures': 38, 'such': 39, 'cnns': 40, 'rnns': 41, 'transformers': 42, 'language': 43, 'autoencoders': 44, 'generative': 45, 'well': 46, 'basic': 47, 'bayesian': 48, 'unsupervised': 49}\n",
            "Vocabulary Size: 49\n",
            "\n",
            "Example: [[2, 3, 16, 1]]\n",
            "\n",
            "Example: [[1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the tokens as different vector representations"
      ],
      "metadata": {
        "id": "7R32BZxmTZI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_documents = [\"data science is awesome\", \"i like ice cream\"]\n",
        "\n",
        "vectors = tokenizer.texts_to_matrix(test_documents, mode='binary')\n",
        "print(\"binary vectors:\", vectors)\n",
        "\n",
        "vectors = tokenizer.texts_to_matrix(test_documents, mode='count')\n",
        "print(\"count vectors:\", vectors)\n",
        "\n",
        "vectors = tokenizer.texts_to_matrix(test_documents, mode='tfidf')\n",
        "print(\"tfidf vectors:\", vectors)"
      ],
      "metadata": {
        "id": "19wS28wuDGk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e3387f-d281-4c0f-e043-6d1dd7002c13"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary vectors: [[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "count vectors: [[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "tfidf vectors: [[0.         0.69314718 0.40546511 0.40546511 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.40546511 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         1.65405321 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **tf.keras: TextVectorization Layer**"
      ],
      "metadata": {
        "id": "3fhvG7FH1s9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set maximum number of words in vocab\n",
        "max_tokens = 45\n",
        "\n",
        "# Initialize Text Vectorizer\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens+2, # 0 is reserved for padding, 1 is reserved for UNK\n",
        "    output_mode=\"int\"\n",
        ")\n",
        "\n",
        "# Fit on text to generate token index and vocabulary\n",
        "text_vectorizer.adapt([input_text])\n",
        "\n",
        "# Get Vocabulary\n",
        "vocabulary = text_vectorizer.get_vocabulary()\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(\"Vocabulary Size:\",vocabulary_size)\n",
        "\n",
        "# Generate word index\n",
        "word_index = dict(zip(vocabulary, range(vocabulary_size)))\n",
        "\n",
        "print(\"vocabulary:\",len(vocabulary),vocabulary)\n",
        "print(\"word_index:\",word_index)\n",
        "\n",
        "print(\"\\nExample:\",text_vectorizer(\"data science is awesome\"))\n",
        "print(\"\\nExample:\",text_vectorizer(\"I like ice cream\"))"
      ],
      "metadata": {
        "id": "d7w3jmsl93kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c90a5c-bd7f-4c83-f88b-d3c055cb2aeb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 47\n",
            "vocabulary: 47 ['', '[UNK]', 'data', 'the', 'science', 'as', 'and', 'topics', 'to', 'models', 'methods', 'learning', 'introduction', 'in', 'advanced', 'wrangling', 'well', 'visualization', 'upon', 'unsupervised', 'transformers', 'such', 'statistical', 'second', 'rnns', 'prediction', 'oneyear', 'of', 'multiple', 'modeling', 'material', 'language', 'is', 'introduces', 'include', 'half', 'generative', 'for', 'deep', 'cs109b', 'course', 'cnns', 'building', 'big', 'bayesian', 'basic', 'autoencoders']\n",
            "word_index: {'': 0, '[UNK]': 1, 'data': 2, 'the': 3, 'science': 4, 'as': 5, 'and': 6, 'topics': 7, 'to': 8, 'models': 9, 'methods': 10, 'learning': 11, 'introduction': 12, 'in': 13, 'advanced': 14, 'wrangling': 15, 'well': 16, 'visualization': 17, 'upon': 18, 'unsupervised': 19, 'transformers': 20, 'such': 21, 'statistical': 22, 'second': 23, 'rnns': 24, 'prediction': 25, 'oneyear': 26, 'of': 27, 'multiple': 28, 'modeling': 29, 'material': 30, 'language': 31, 'is': 32, 'introduces': 33, 'include': 34, 'half': 35, 'generative': 36, 'for': 37, 'deep': 38, 'cs109b': 39, 'course': 40, 'cnns': 41, 'building': 42, 'big': 43, 'bayesian': 44, 'basic': 45, 'autoencoders': 46}\n",
            "\n",
            "Example: tf.Tensor([ 2  4 32  1], shape=(4,), dtype=int64)\n",
            "\n",
            "Example: tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the tokens as different vector representations"
      ],
      "metadata": {
        "id": "DeufigppTka_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary 1-gram bag-of-words"
      ],
      "metadata": {
        "id": "kC4-_lMn2wYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Text Vectorizer\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens+2,\n",
        "    output_mode=\"multi_hot\"\n",
        ")\n",
        "# Fit on text to generate token index and vocabulary\n",
        "text_vectorizer.adapt([input_text])\n",
        "\n",
        "print(\"Vocabulary:\",text_vectorizer.get_vocabulary())\n",
        "print(\"\\nExample:\",text_vectorizer(\"data science is awesome\"))\n",
        "print(\"\\nExample:\",text_vectorizer(\"I like ice cream\"))"
      ],
      "metadata": {
        "id": "O6vptG1ITXjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9874599-6a3f-4f90-8aaf-a7c41bebf92c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['[UNK]', 'data', 'the', 'science', 'as', 'and', 'topics', 'to', 'models', 'methods', 'learning', 'introduction', 'in', 'advanced', 'wrangling', 'well', 'visualization', 'upon', 'unsupervised', 'transformers', 'such', 'statistical', 'second', 'rnns', 'prediction', 'oneyear', 'of', 'multiple', 'modeling', 'material', 'language', 'is', 'introduces', 'include', 'half', 'generative', 'for', 'deep', 'cs109b', 'course', 'cnns', 'building', 'big', 'bayesian', 'basic', 'autoencoders', 'architectures']\n",
            "\n",
            "Example: tf.Tensor(\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(47,), dtype=float32)\n",
            "\n",
            "Example: tf.Tensor(\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(47,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram bag-of-words"
      ],
      "metadata": {
        "id": "pQFyuSXx2ykc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Text Vectorizer\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    output_mode=\"count\"\n",
        ")\n",
        "# Fit on text to generate token index and vocabulary\n",
        "text_vectorizer.adapt([input_text])\n",
        "\n",
        "print(\"Vocabulary:\",text_vectorizer.get_vocabulary())\n",
        "print(\"\\nExample:\",text_vectorizer(\"data science is awesome\"))\n",
        "print(\"\\nExample:\",text_vectorizer(\"I like ice cream\"))"
      ],
      "metadata": {
        "id": "NdOj3O8gZLKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1214cd12-e979-424d-f6f1-445370a7c275"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['[UNK]', 'data', 'the', 'science', 'data science', 'as', 'and', 'topics', 'to data', 'to', 'models', 'methods', 'learning', 'introduction to', 'introduction', 'in', 'advanced', 'wrangling data', 'wrangling', 'well as', 'well', 'visualization statistical', 'visualization', 'upon the', 'upon', 'unsupervised learning', 'unsupervised', 'transformers language', 'transformers', 'topics include', 'topics in', 'the second', 'the material', 'the course', 'such as', 'such', 'statistical modeling', 'statistical', 'second half', 'second', 'science the', 'science cs109b', 'science building', 'rnns transformers', 'rnns', 'prediction topics', 'prediction', 'oneyear introduction', 'oneyear', 'of a', 'of', 'multiple deep', 'multiple', 'models autoencoders', 'models as', 'modeling and', 'modeling', 'methods for', 'methods and', 'material in', 'material', 'learning architectures', 'language models', 'language', 'is the', 'is', 'introduces advanced', 'introduces', 'include big', 'include', 'in introduction', 'in data', 'half of', 'half', 'generative models', 'generative', 'for data', 'for', 'deep learning', 'deep', 'data wrangling', 'data visualization', 'data multiple', 'cs109b is', 'cs109b', 'course introduces', 'course', 'cnns rnns', 'cnns', 'building upon', 'building', 'big data', 'big', 'bayesian methods', 'bayesian', 'basic bayesian', 'basic', 'autoencoders and', 'autoencoders', 'as well', 'as cnns', 'as basic', 'architectures such', 'architectures', 'and unsupervised', 'and prediction', 'and generative', 'advanced topics', 'advanced methods', 'a oneyear', 'a']\n",
            "\n",
            "Example: tf.Tensor(\n",
            "[3. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(111,), dtype=float32)\n",
            "\n",
            "Example: tf.Tensor(\n",
            "[7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(111,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recurrent Neural Networks**"
      ],
      "metadata": {
        "id": "4GuUTg9LbFZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is to get you familiar with different RNN architectures. We will be working with a Named Entity Recognition (NER) dataset."
      ],
      "metadata": {
        "id": "_u60Fcq2cls5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the data**\n",
        "\n",
        "The dataset contains all the sentences, with each word tagged. </br>\n",
        "The tags can be:\n",
        "* geo = Geographical Entity\n",
        "* org = Organization\n",
        "* per = Person\n",
        "* gpe = Geopolitical Entity\n",
        "* tim = Time indicator\n",
        "* art = Artifact\n",
        "* eve = Event\n",
        "* nat = Natural Phenomenon\n",
        "\n",
        "Extract each sentence and transform it into an adequate format.  Use **df.fillna(method='ffill', inplace=True)** to fill the NaN values and extract the values easily.</br>"
      ],
      "metadata": {
        "id": "Ch1PniWbcb4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_csv('https://storage.googleapis.com/dataset_store/nlp/ner_dataset.csv', \n",
        "                 encoding= 'unicode_escape', \n",
        "                 usecols=['Sentence #','Word','Tag'])\n",
        "\n",
        "# Take a quick look at the dataset\n",
        "print(\"Shape:\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "7m4ZNwuWbiU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "17cf1ebd-9085-44e5-e700-ee5b071b93ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1048575, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word Tag\n",
              "0  Sentence: 1      Thousands   O\n",
              "1          NaN             of   O\n",
              "2          NaN  demonstrators   O\n",
              "3          NaN           have   O\n",
              "4          NaN        marched   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7743d3ae-d884-4a56-81c0-08624aca93f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7743d3ae-d884-4a56-81c0-08624aca93f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7743d3ae-d884-4a56-81c0-08624aca93f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7743d3ae-d884-4a56-81c0-08624aca93f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Data Pipelines**"
      ],
      "metadata": {
        "id": "0c0tJ5KPeynR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean Data**"
      ],
      "metadata": {
        "id": "j6I9Wv7te2sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The sentence is marked only at the first word with NaNs for the rest of the cells. We need to fill them with sentence number"
      ],
      "metadata": {
        "id": "cUW9mzc35giM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We fill Nan values using the previous value. \n",
        "# This way we can separate each sentence.\n",
        "data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Remove \"Sentence: \" from the sentence column\n",
        "data['Sentence #'] = data['Sentence #'].str.replace('Sentence: ','').astype(int)\n",
        "\n",
        "# Set the index as the sentence number. Then we filter each sentence, joininig the text\n",
        "data.set_index('Sentence #', inplace=True)\n",
        "\n",
        "print(\"Shape:\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "AIfDCNAgrAmG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "bc4d617e-0975-429a-b144-c5701fe03518"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1048575, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Word Tag\n",
              "Sentence #                   \n",
              "1               Thousands   O\n",
              "1                      of   O\n",
              "1           demonstrators   O\n",
              "1                    have   O\n",
              "1                 marched   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b6d9ff2-afb0-4dd3-83bb-624b273cfb35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentence #</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b6d9ff2-afb0-4dd3-83bb-624b273cfb35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b6d9ff2-afb0-4dd3-83bb-624b273cfb35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b6d9ff2-afb0-4dd3-83bb-624b273cfb35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a quick look at the different tags\n",
        "print(data[\"Tag\"].unique())\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.hist(data[\"Tag\"], log=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lUaMtHVArLXY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "52ef9fc0-3e85-49c6-cbeb-de659cf98a65"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
            " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at the first sentence"
      ],
      "metadata": {
        "id": "3X6was11_YMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first sentence\n",
        "sentence = data.loc[1]\n",
        "for index, row in sentence.iterrows():\n",
        "  print(row[\"Word\"],\"->\",row[\"Tag\"])"
      ],
      "metadata": {
        "id": "bEIKIUbV_aqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bab7296-5f5c-4689-808f-139f9ddba203"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thousands -> O\n",
            "of -> O\n",
            "demonstrators -> O\n",
            "have -> O\n",
            "marched -> O\n",
            "through -> O\n",
            "London -> B-geo\n",
            "to -> O\n",
            "protest -> O\n",
            "the -> O\n",
            "war -> O\n",
            "in -> O\n",
            "Iraq -> B-geo\n",
            "and -> O\n",
            "demand -> O\n",
            "the -> O\n",
            "withdrawal -> O\n",
            "of -> O\n",
            "British -> B-gpe\n",
            "troops -> O\n",
            "from -> O\n",
            "that -> O\n",
            "country -> O\n",
            ". -> O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select sentences with more than 15 and less than 30 words."
      ],
      "metadata": {
        "id": "snVlNqWop1l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the dataframe by sequence length\n",
        "index, length = np.unique(data.index, return_counts=True)\n",
        "\n",
        "b1 = length>15\n",
        "b2 = length<30\n",
        "b = np.logical_and(b1, b2)\n",
        "\n",
        "index = index[b]\n",
        "length = length[b]\n",
        "\n",
        "data = data.loc[index]\n",
        "\n",
        "print(\"length\",length)\n",
        "# Take a quick look at the dataset\n",
        "print(\"Shape:\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "mdyVMdNbptAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "89eb34e2-af59-46fe-ee3c-20886119db04"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length [24 25 24 ... 29 20 24]\n",
            "Shape: (653765, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Word Tag\n",
              "Sentence #                   \n",
              "1               Thousands   O\n",
              "1                      of   O\n",
              "1           demonstrators   O\n",
              "1                    have   O\n",
              "1                 marched   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf250d35-e705-4979-9519-4f95f6e3809b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentence #</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf250d35-e705-4979-9519-4f95f6e3809b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf250d35-e705-4979-9519-4f95f6e3809b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf250d35-e705-4979-9519-4f95f6e3809b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize**"
      ],
      "metadata": {
        "id": "-3PBDpv_p_2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the tags into labels using LabelEnconder\n",
        "le = LabelEncoder()\n",
        "data['Tag'] = le.fit_transform(data.Tag)\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None,\n",
        "                                                filters='\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                                lower=True,\n",
        "                                                split=' ',)\n",
        "# Fit on entire text\n",
        "tokenizer.fit_on_texts(data.Word.values)\n",
        "\n",
        "# Transform to tokens\n",
        "tokens = tokenizer.texts_to_sequences(data.Word.values)\n",
        "\n",
        "# Remove empty elements\n",
        "b = np.array([token!=[] for token in tokens])\n",
        "data = data.iloc[b,:]\n",
        "tokens = np.array(tokens, dtype=object)[b]\n",
        "\n",
        "data.Word = tokens\n",
        "data.Word=data.Word.map(lambda x: x[0])\n",
        "\n",
        "\n",
        "print(\"Shape:\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "2gxki76hptDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e1d3ef67-a723-4a77-c0a4-c0d20907e0f8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (600549, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Word  Tag\n",
              "Sentence #           \n",
              "1            248   16\n",
              "1              3   16\n",
              "1            859   16\n",
              "1             14   16\n",
              "1           1501   16"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e570c5d2-4870-4f3a-b7ae-f33dbfa041e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentence #</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>248</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>859</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1501</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e570c5d2-4870-4f3a-b7ae-f33dbfa041e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e570c5d2-4870-4f3a-b7ae-f33dbfa041e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e570c5d2-4870-4f3a-b7ae-f33dbfa041e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first sentence\n",
        "test_sentence = data.loc[1]\n",
        "for index, row in test_sentence.iterrows():\n",
        "  print(row[\"Word\"],\"->\",row[\"Tag\"])"
      ],
      "metadata": {
        "id": "f2VArX9IrDiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179a0fea-be25-4b43-fecf-b885500f90c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "248 -> 16\n",
            "3 -> 16\n",
            "859 -> 16\n",
            "14 -> 16\n",
            "1501 -> 16\n",
            "238 -> 16\n",
            "472 -> 2\n",
            "5 -> 16\n",
            "490 -> 16\n",
            "1 -> 16\n",
            "124 -> 16\n",
            "2 -> 16\n",
            "57 -> 2\n",
            "6 -> 16\n",
            "590 -> 16\n",
            "1 -> 16\n",
            "812 -> 16\n",
            "3 -> 16\n",
            "178 -> 3\n",
            "85 -> 16\n",
            "21 -> 16\n",
            "12 -> 16\n",
            "50 -> 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data by building the sentences from each word \n",
        "IDs = data.index.unique()\n",
        "\n",
        "sentences = []\n",
        "tags = []\n",
        "Ns = []\n",
        "for i in IDs: # For each id for the sentence\n",
        "    sel = data.loc[i] # We extract the respective data\n",
        "    if len(sel.shape)<2: # If the data is not formatted properly\n",
        "        continue # Ommit that id\n",
        "        \n",
        "    sentence = sel.Word.values # A sentence is a list of tokens\n",
        "    tag = sel['Tag'].values # The tags correspond to each token\n",
        "    \n",
        "    sentences.append(sentence)  # We store the sentences in a list\n",
        "    tags.append(tag)            # We do the same with the tags\n",
        "    Ns.append(sentence.shape[0])# And store the length of the sentence\n",
        "    \n",
        "# We transform everything into np arrays    \n",
        "Ns = np.array(Ns)\n",
        "sentences = np.array(sentences, dtype=object)\n",
        "tags = np.array(tags, dtype=object)    \n",
        "\n",
        "# To speed up calculations, we filter by sequence length\n",
        "# We do not care much of long sentences.\n",
        "b1 = Ns>15\n",
        "b2 = Ns<30\n",
        "b = np.logical_and(b1, b2)\n",
        "\n",
        "# We filter the training set\n",
        "Ns = Ns[b]\n",
        "sentences = sentences[b]\n",
        "tags = tags[b]\n",
        "\n",
        "# For simplicity, we create a padded array beforehand\n",
        "sentences = tf.keras.preprocessing.sequence.pad_sequences(sentences, padding='post')\n",
        "tags = tf.keras.preprocessing.sequence.pad_sequences(tags, padding='post')\n",
        "\n",
        "print(\"Shape:\",sentences.shape)"
      ],
      "metadata": {
        "id": "POq19OMarZ8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd15498-8f26-4858-ee39-af4f3d1d5de3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (26521, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View some data\n",
        "for idx in range(3):\n",
        "  print(\"Input\",len(sentences[idx]), sentences[idx])\n",
        "  print(\"Output\",len(tags[idx]),tags[idx])\n",
        "  print(\"*************\")"
      ],
      "metadata": {
        "id": "yJDFIxrnuapb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d55ae29-fe14-498e-b22a-2a46f2ac90bc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 28 [ 248    3  859   14 1501  238  472    5  490    1  124    2   57    6\n",
            "  590    1  812    3  178   85   21   12   50    0    0    0    0    0]\n",
            "Output 28 [16 16 16 16 16 16  2 16 16 16 16 16  2 16 16 16 16 16  3 16 16 16 16  0\n",
            "  0  0  0  0]\n",
            "*************\n",
            "Input 28 [    1   490   532    10     1  1928     3     1  1079   460     3   403\n",
            "     7   487   831   139     2     1   125  2429  8837  1453     3 13911\n",
            "     0     0     0     0]\n",
            "Output 28 [16 16 16 16 16 16 16 16 16 16 16  2 16 16  5 13 16 16 16  3 16 16 16  2\n",
            "  0  0  0  0]\n",
            "*************\n",
            "Input 28 [   1  139   11 1749   84  403    7 3158    2    1   57  609    6    1\n",
            "  718 2100    3  528  178   85    2   12   50    0    0    0    0    0]\n",
            "Output 28 [16 16 16 16 16  3 16 16 16 16  2 16 16 16 16 16 16 16  3 16 16 16 16  0\n",
            "  0  0  0  0]\n",
            "*************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split data into train and validation by randomly selecting 20% as the validation set."
      ],
      "metadata": {
        "id": "pDenaWeyu1k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "validation_percent = 0.20\n",
        "\n",
        "# Split data into train / validate\n",
        "train_x, validate_x, train_y, validate_y = train_test_split(sentences, tags, test_size=validation_percent)\n",
        "\n",
        "print(\"train_x count:\",len(train_x))\n",
        "print(\"validate_x count:\",len(validate_x))"
      ],
      "metadata": {
        "id": "6tlYFFCpu1k_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc95629-e467-4734-eddb-f9e082593214"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x count: 21216\n",
            "validate_x count: 5305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique labels\n",
        "num_classes = le.classes_.shape[0] \n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "print(\"Vocabulary Size:\",vocabulary_size)"
      ],
      "metadata": {
        "id": "Np420ai8KiVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeac6524-f7ff-4bb1-d506-a514aea54bfb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 17\n",
            "Vocabulary Size: 22817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Single Layer RNN**"
      ],
      "metadata": {
        "id": "HcDMizUpvpAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**\n",
        "\n",
        "Define a model, which will be many to many.\n",
        "\n",
        "* The first layer should be Embedding, with _mask_zero_ set to True. This will propagate the mask in the network.\n",
        "* Then, a SimpleRNN layer. We set here the number of hidden units. Remember to return the sequence of hidden states.\n",
        "* We will define a Dense layer, with size set as the number of classes and activation softmax. "
      ],
      "metadata": {
        "id": "jFp79PR2vtWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_single_rnn(num_classes,vocab_size,embedding_dim):\n",
        "  # Model input\n",
        "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
        "\n",
        "  # Embedding\n",
        "  hidden = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
        "                        name='word_embedding', mask_zero=True)(model_input)\n",
        "\n",
        "  # Forward RNN layer\n",
        "  hidden = tf.keras.layers.SimpleRNN(units=embedding_dim, return_sequences=True)(hidden)\n",
        "\n",
        "  # Output Layer\n",
        "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(hidden)\n",
        "\n",
        "  # Create model\n",
        "  model = tf.keras.Model(inputs=model_input, outputs=output, name=\"single_rnn\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "8GCkLWj8rjA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "tyoHmIR0GBax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "embedding_dim = 8\n",
        "\n",
        "# Free up memory\n",
        "K.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model = build_single_rnn(num_classes,vocabulary_size, embedding_dim)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Loss\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_x,train_y,\n",
        "        validation_data= (validate_x,validate_y),\n",
        "        batch_size=1024,\n",
        "        epochs=epochs, \n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "T0kZBsE_Fhgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bbc73f-d3b6-44ff-c134-3fb7b5a9eeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"single_rnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sentence_input (InputLayer)  [(None, None)]           0         \n",
            "                                                                 \n",
            " word_embedding (Embedding)  (None, None, 8)           182544    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 8)           136       \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 17)          153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 182,833\n",
            "Trainable params: 182,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "21/21 [==============================] - 5s 56ms/step - loss: 1.9621 - accuracy: 0.5501 - val_loss: 1.7625 - val_accuracy: 0.8303\n",
            "Epoch 2/20\n",
            "21/21 [==============================] - 1s 33ms/step - loss: 1.6059 - accuracy: 0.8308 - val_loss: 1.4468 - val_accuracy: 0.8313\n",
            "Epoch 3/20\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 1.3385 - accuracy: 0.8309 - val_loss: 1.2267 - val_accuracy: 0.8313\n",
            "Epoch 4/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 1.1439 - accuracy: 0.8309 - val_loss: 1.0561 - val_accuracy: 0.8313\n",
            "Epoch 5/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 0.9915 - accuracy: 0.8309 - val_loss: 0.9239 - val_accuracy: 0.8313\n",
            "Epoch 6/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 0.8775 - accuracy: 0.8309 - val_loss: 0.8295 - val_accuracy: 0.8313\n",
            "Epoch 7/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.7989 - accuracy: 0.8309 - val_loss: 0.7671 - val_accuracy: 0.8313\n",
            "Epoch 8/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 0.7472 - accuracy: 0.8309 - val_loss: 0.7257 - val_accuracy: 0.8314\n",
            "Epoch 9/20\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 0.7121 - accuracy: 0.8311 - val_loss: 0.6969 - val_accuracy: 0.8316\n",
            "Epoch 10/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.6867 - accuracy: 0.8313 - val_loss: 0.6750 - val_accuracy: 0.8317\n",
            "Epoch 11/20\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 0.6665 - accuracy: 0.8313 - val_loss: 0.6567 - val_accuracy: 0.8317\n",
            "Epoch 12/20\n",
            "21/21 [==============================] - 1s 36ms/step - loss: 0.6490 - accuracy: 0.8314 - val_loss: 0.6403 - val_accuracy: 0.8317\n",
            "Epoch 13/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.6325 - accuracy: 0.8313 - val_loss: 0.6245 - val_accuracy: 0.8316\n",
            "Epoch 14/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 0.6159 - accuracy: 0.8313 - val_loss: 0.6083 - val_accuracy: 0.8317\n",
            "Epoch 15/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.5985 - accuracy: 0.8318 - val_loss: 0.5909 - val_accuracy: 0.8323\n",
            "Epoch 16/20\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 0.5798 - accuracy: 0.8322 - val_loss: 0.5725 - val_accuracy: 0.8324\n",
            "Epoch 17/20\n",
            "21/21 [==============================] - 1s 35ms/step - loss: 0.5599 - accuracy: 0.8324 - val_loss: 0.5530 - val_accuracy: 0.8326\n",
            "Epoch 18/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.5390 - accuracy: 0.8328 - val_loss: 0.5329 - val_accuracy: 0.8337\n",
            "Epoch 19/20\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 0.5177 - accuracy: 0.8364 - val_loss: 0.5125 - val_accuracy: 0.8401\n",
            "Epoch 20/20\n",
            "21/21 [==============================] - 1s 37ms/step - loss: 0.4965 - accuracy: 0.8435 - val_loss: 0.4926 - val_accuracy: 0.8446\n",
            "Training execution time (mins) 0.3166996995608012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training results\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "axs = fig.add_subplot(1,3,1)\n",
        "axs.set_title('Loss')\n",
        "# Plot all metrics\n",
        "for metric in [\"loss\",\"val_loss\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "axs = fig.add_subplot(1,3,2)\n",
        "axs.set_title('Accuracy')\n",
        "# Plot all metrics\n",
        "for metric in [\"accuracy\",\"val_accuracy\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5yHNyWgFFhjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "dcd29707-0e03-4106-cbe6-20f5c2a97535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Various Models Architectures üéäüéâ**\n",
        "\n",
        "### **<font color='red'>Activity</font> üéäüéâ** \n",
        "\n",
        "\n",
        "**Create the following architectures:**\n",
        "\n",
        "Create a function to build different RNN architectures. For simplicity, use the SimpleRNN.\n",
        "\n",
        "* Create a single-layer RNN network \n",
        "* Create a k-layer RNN network, where k=[2,3]. \n",
        "* Create a bidirectional single-layer RNN.  \n",
        "* Create a bidirectional k-layer RNN, where k=[2,3]. "
      ],
      "metadata": {
        "id": "bCSwNl-eLQdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for all model options\n",
        "def build_model(num_classes,vocab_size,embedding_dim,rnn_layers,bidir):\n",
        "  # Model input\n",
        "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
        "\n",
        "  # Embedding\n",
        "  hidden = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
        "                        name='word_embedding', mask_zero=True)(model_input)\n",
        "\n",
        "  # Create RNNs\n",
        "  hidden_forward = []\n",
        "  hidden_backward = []\n",
        "  for k in range(rnn_layers):\n",
        "    # Forward RNN layer\n",
        "    hidden = tf.keras.layers.SimpleRNN(units=embedding_dim, return_sequences=True)(hidden)\n",
        "    hidden_forward.append(hidden)\n",
        "\n",
        "    # Backward RNN layer\n",
        "    if bidir:\n",
        "      hidden_b = tf.keras.layers.SimpleRNN(units=embedding_dim, return_sequences=True, go_backwards=True)(hidden)\n",
        "      hidden_backward.append(hidden_b)\n",
        "  \n",
        "  if bidir:\n",
        "      hidden = tf.keras.layers.concatenate(hidden_forward+hidden_backward)\n",
        "  else:\n",
        "      if rnn_layers==1:\n",
        "          hidden = hidden_forward[0]\n",
        "      else:\n",
        "          hidden = tf.keras.layers.concatenate(hidden_forward)\n",
        "\n",
        "  # Output Layer\n",
        "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(hidden)\n",
        "\n",
        "  # Create model\n",
        "  model = tf.keras.Model(inputs=model_input, outputs=output, name='_'.join([str(embedding_dim), str(rnn_layer),str(bidir)]))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "nU0JzCXhFhlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**"
      ],
      "metadata": {
        "id": "oPeZYx5t-GBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_solution(\"https://storage.googleapis.com/public-code-snippets/cs109b_lab9_activity1.txt\")"
      ],
      "metadata": {
        "id": "XH4PPLoMAXpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4178447-4399-4c5b-ac3a-08c93c5a9b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Create a function for all model options\n",
            "def build_model(num_classes,vocab_size,embedding_dim,rnn_layers,bidir):\n",
            "  # Model input\n",
            "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
            "\n",
            "  # Embedding\n",
            "  hidden = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
            "                        name='word_embedding', mask_zero=True)(model_input)\n",
            "\n",
            "  # Create RNNs\n",
            "  hidden_forward = []\n",
            "  hidden_backward = []\n",
            "  for k in range(rnn_layers):\n",
            "    # Forward RNN layer\n",
            "    hidden = tf.keras.layers.SimpleRNN(units=embedding_dim, return_sequences=True)(hidden)\n",
            "    hidden_forward.append(hidden)\n",
            "\n",
            "    # Backward RNN layer\n",
            "    if bidir:\n",
            "      hidden_b = tf.keras.layers.SimpleRNN(units=embedding_dim, return_sequences=True, go_backwards=True)(hidden)\n",
            "      hidden_backward.append(hidden_b)\n",
            "  \n",
            "  if bidir:\n",
            "      hidden = tf.keras.layers.concatenate(hidden_forward+hidden_backward)\n",
            "  else:\n",
            "      if rnn_layers==1:\n",
            "          hidden = hidden_forward[0]\n",
            "      else:\n",
            "          hidden = tf.keras.layers.concatenate(hidden_forward)\n",
            "\n",
            "  # Output Layer\n",
            "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(hidden)\n",
            "\n",
            "  # Create model\n",
            "  model = tf.keras.Model(inputs=model_input, outputs=output, name='_'.join([str(embedding_dim), str(rnn_layer),str(bidir)]))\n",
            "\n",
            "  return model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run each model experiment with the following training parameters"
      ],
      "metadata": {
        "id": "19N4Gj-hsQuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate=0.001\n",
        "epochs = 20\n",
        "embedding_dim = [32,64] # [8,32,64]\n",
        "num_rnn_layers = [1,2] # [2,3]\n",
        "\n",
        "all_training_results = []\n",
        "\n",
        "for e_dim in embedding_dim:\n",
        "  for rnn_layer in num_rnn_layers:\n",
        "    for bidir in [False,True]:\n",
        "      # Free up memory\n",
        "      K.clear_session()\n",
        "\n",
        "      # Build the model\n",
        "      model = build_model(num_classes,vocabulary_size, e_dim, rnn_layer, bidir)\n",
        "\n",
        "      # Print the model architecture\n",
        "      print(model.name)\n",
        "      #print(model.summary())\n",
        "\n",
        "      # Optimizer\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "      # Loss\n",
        "      loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "      # Compile\n",
        "      model.compile(loss=loss,\n",
        "                        optimizer=optimizer,\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "      # Train model\n",
        "      start_time = time.time()\n",
        "      training_results = model.fit(\n",
        "              train_x,train_y,\n",
        "              validation_data= (validate_x,validate_y),\n",
        "              batch_size=1024,\n",
        "              epochs=epochs, \n",
        "              verbose=0)\n",
        "      all_training_results.append(training_results)\n",
        "      execution_time = (time.time() - start_time)/60.0\n",
        "      print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "0hjCX7vMLqoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "d87e19f7-6f46-4820-ddc9-1e898bacaed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32_1_False\n",
            "Training execution time (mins) 0.28096869389216106\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-3aaaaf562845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m# Build the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;31m# Print the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-8c2342627a4b>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(num_classes, vocab_size, embedding_dim, rnn_layers, bidir)\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbidir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# If bi directional concatenate hidden_forward and hidden_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_backward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrnn_layers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m   \"\"\"\n\u001b[0;32m--> 968\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m       raise ValueError(\n\u001b[0;32m--> 502\u001b[0;31m           \u001b[0;34m'A `Concatenate` layer should be called on a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m           f'at least 1 input. Received: input_shape={input_shape}')\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer should be called on a list of at least 1 input. Received: input_shape=[[(None, None, 32)], [(None, None, 32)]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Models**"
      ],
      "metadata": {
        "id": "QBWEEPyqM4-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the results\n",
        "plt.figure(figsize=(15,10))\n",
        "for training_results in all_training_results:\n",
        "    plt.plot(training_results.history['val_loss'], label=training_results.model.name)\n",
        "plt.legend(loc=0)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6vApdka6Lqxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "for training_results in all_training_results:\n",
        "    plt.plot(training_results.history['val_accuracy'], label=training_results.model.name)\n",
        "plt.legend(loc=0)\n",
        "plt.ylim(0.8,1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BaoZz3haM9Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which model is performing well?"
      ],
      "metadata": {
        "id": "MRkMqGepskvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTMs**"
      ],
      "metadata": {
        "id": "5wT9IIKMZJlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the data**"
      ],
      "metadata": {
        "id": "xOQxeAfeZbuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "file_path = \"https://storage.googleapis.com/cs109b/nlp/imdb.csv\"\n",
        "data = pd.read_csv(file_path, encoding='latin1')\n",
        "print(\"Shape:\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "u6d1jPy3Zbuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6e89f0a8-457c-45c1-9747-83e3aceacbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (10000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  polarity\n",
              "0  first think another Disney movie, might good, ...         1\n",
              "1  Put aside Dr. House repeat missed, Desperate H...         0\n",
              "2  big fan Stephen King's work, film made even gr...         1\n",
              "3  watched horrid thing TV. Needless say one movi...         0\n",
              "4  truly enjoyed film. acting terrific plot. Jeff...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d10295a1-bae7-4763-ba12-dbfeb46cecd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>big fan Stephen King's work, film made even gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d10295a1-bae7-4763-ba12-dbfeb46cecd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d10295a1-bae7-4763-ba12-dbfeb46cecd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d10295a1-bae7-4763-ba12-dbfeb46cecd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data x and y\n",
        "data_x = data[\"text\"].values\n",
        "data_y = data[\"polarity\"].values\n",
        "\n",
        "# Number of unique labels\n",
        "num_classes = len(np.unique(data_y))\n",
        "print(\"Number of classes:\", num_classes)\n",
        "\n",
        "print(\"data_x:\",len(data_x))\n",
        "print(\"data_y:\",len(data_y))\n",
        "print(\"data_x:\",data_x[:5])\n",
        "print(\"data_y:\",data_y[:5])"
      ],
      "metadata": {
        "id": "7njEUztMtFtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7be529f-7591-4043-c3c5-d6532eea0a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 2\n",
            "data_x: 10000\n",
            "data_y: 10000\n",
            "data_x: [\"first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\"\n",
            " 'Put aside Dr. House repeat missed, Desperate Housewives (new) watch one. don\\'t know exactly plagued movie. never thought I\\'d say this, want 15 minutes fame back.<br /><br />Script, Direction, can\\'t say. recognized stable actors (the usual suspects), thought Herbert Marshall class addition sat good cheesy flick. Boy, wrong. Dullsville.<br /><br />My favorite parts: \"office girl\" makes 029 keypunch puts cards 087 sorter. LOL @ \"the computer\". I\\'d like someone identify next device - 477 ? It\\'s even dinosaur\\'s time.<br /><br />And dinosaurs don\\'t much time waste.'\n",
            " 'big fan Stephen King\\'s work, film made even greater fan King. Pet Sematary Creed family. moved new house, seem happy. pet cemetery behind house. Creed\\'s new neighbor Jud (played Fred Gwyne) explains burial ground behind pet cemetery. burial ground pure evil. Jud tells Louis Creed bury human (or kind pet) burial ground, would come back life. problem, come back, person, they\\'re evil. Soon Jud explains everything Pet Sematary, everything starts go hell. wont explain anymore don\\'t want give away main parts film. acting Pet Sematary pretty good, needed little bit work. story one main parts movie, mainly original gripping. film features lots make-up effects make movie way eerie, frightening. One basic reasons movie sent chills back, fact make-up effects. one character film truly freaky. character \"Zelda.\" particular character pops film three times precise. Zelda Rachel Creed\\'s sister passed away years before, Rachel still haunted her. first time Zelda appears movie isn\\'t generally scary isn\\'t talking anything, second time worst, honest, second time scares living **** me. absolutely nothing wrong movie, almost perfect. Pet Sematary delivers great scares, pretty good acting, first rate plot, mesmerizing make-up. truly one favorite horror films time. 10 10.'\n",
            " 'watched horrid thing TV. Needless say one movies watch see much worse get. Frankly, don\\'t know much lower bar go. <br /><br />The characters composed one lame stereo-type another, obvious attempt creating another \"Bad News Bears\" embarrassing say least.<br /><br />I seen prized turkeys time, reason list since \"Numero Uno\".<br /><br />Let put way, watched Vanilla Ice movie, bad funny. This...this...is even good.'\n",
            " \"truly enjoyed film. acting terrific plot. Jeff Combs talent recognized for. part flick would change ending. death creature far gruesome Sci Fi Channel.<br /><br />There interesting religious messages film. Jeff Combs obviously played Messiah figure creature (or shark prefer) represented anti-Chirst. particularly frightening scenes 'end world feel'. noticed third viewing classic creature feature. know many people won't get references Christianity, watch close you'll get it.\"]\n",
            "data_y: [1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Data Pipelines**"
      ],
      "metadata": {
        "id": "oAGfg61ZZbud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data** "
      ],
      "metadata": {
        "id": "nbMP2Tw3Zbue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split data into train and validation by randomly selecting 20% as the test set."
      ],
      "metadata": {
        "id": "s-u197VeZbue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "validation_percent = 0.20\n",
        "\n",
        "# Split data into train / validate\n",
        "train_x, validate_x, train_y, validate_y = train_test_split(data_x, data_y, test_size=validation_percent, stratify=data_y)\n",
        "\n",
        "print(\"train_x count:\",len(train_x))\n",
        "print(\"validate_x count:\",len(validate_x))"
      ],
      "metadata": {
        "id": "3mocTngXKerG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75daec7d-0d0b-47b2-8771-9a8569f70233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x count: 8000\n",
            "validate_x count: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Tokenization**"
      ],
      "metadata": {
        "id": "JrIlzVO8IMsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tokenizer with vocabulary size of 10,000 that filters all special characters and \n",
        "# converts the characters to lowercase\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000,\n",
        "                                                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                                  lower=True,\n",
        "                                                  split=' ',\n",
        "                                                  char_level=True,)\n",
        "\n",
        "# Fit the tokenizer on the comments column of the train set\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "# Convert the text to tokens\n",
        "train_token_x = tokenizer.texts_to_sequences(train_x)\n",
        "validate_token_x = tokenizer.texts_to_sequences(validate_x)\n",
        "\n",
        "print(\"train_x len :\",len(train_token_x))\n",
        "print(\"train_x:\",train_token_x[:5])\n",
        "print(\"validate_token_x len :\",len(validate_token_x))\n",
        "print(\"validate_token_x:\",validate_token_x[:5])\n",
        "\n",
        "vocabulary_size = tokenizer.num_words\n",
        "print(\"Vocabulary Size:\",vocabulary_size)"
      ],
      "metadata": {
        "id": "q-gFUEk3Zbue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af0a858-4ee2-4cf8-b85a-41371fc8aa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x len : 8000\n",
            "train_x: [[4, 8, 8, 4, 1, 35, 12, 14, 4, 7, 10, 9, 5, 5, 2, 1, 19, 15, 7, 25, 2, 34, 24, 1, 23, 2, 7, 16, 2, 1, 17, 15, 19, 2, 7, 5, 18, 24, 1, 19, 2, 16, 3, 8, 6, 1, 6, 5, 7, 4, 8, 16, 2, 1, 11, 7, 2, 4, 13, 6, 1, 6, 5, 4, 7, 5, 1, 4, 21, 21, 2, 12, 5, 3, 8, 16, 1, 7, 2, 4, 10, 1, 10, 3, 21, 2, 31, 31, 2, 6, 17, 2, 12, 3, 4, 10, 10, 18, 1, 3, 8, 23, 9, 10, 23, 3, 8, 16, 1, 19, 9, 18, 1, 8, 4, 13, 2, 11, 1, 13, 4, 7, 25, 1, 35, 2, 10, 10, 3, 9, 5, 5, 1, 6, 17, 3, 2, 7, 6, 34, 1, 13, 2, 2, 5, 6, 1, 11, 7, 2, 4, 13, 6, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 23, 2, 7, 18, 1, 15, 8, 15, 6, 15, 4, 10, 1, 21, 4, 8, 5, 4, 6, 18, 1, 5, 7, 15, 10, 18, 1, 5, 2, 7, 7, 3, 21, 18, 3, 8, 16, 1, 13, 9, 13, 2, 8, 5, 6, 20, 1, 11, 2, 6, 17, 3, 5, 2, 1, 21, 4, 12, 5, 1, 5, 2, 2, 8, 4, 16, 2, 1, 16, 3, 7, 10, 1, 17, 16, 31, 41, 47, 1, 7, 4, 5, 3, 8, 16, 24, 1, 12, 14, 3, 10, 11, 7, 2, 8, 20, 1, 4, 10, 6, 9, 24, 1, 14, 4, 5, 2, 1, 21, 4, 8, 5, 4, 6, 3, 2, 6, 1, 6, 5, 4, 18, 1, 21, 4, 7, 1, 4, 22, 4, 18, 20, 1, 18, 9, 15, 26, 7, 2, 1, 16, 4, 13, 2, 1, 6, 9, 13, 2, 5, 14, 3, 8, 16, 1, 11, 3, 21, 21, 2, 7, 2, 8, 5, 1, 21, 3, 5, 6, 1, 19, 3, 10, 10, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 22, 2, 10, 10, 1, 11, 3, 7, 2, 12, 5, 2, 11, 1, 19, 2, 7, 8, 4, 7, 11, 1, 7, 9, 6, 2, 1, 19, 2, 4, 15, 5, 3, 21, 15, 10, 1, 13, 15, 6, 3, 12, 1, 6, 12, 9, 7, 2, 1, 8, 3, 12, 2, 24, 1, 6, 12, 4, 7, 18, 1, 33, 9, 10, 5, 6, 20, 1, 5, 14, 3, 8, 16, 1, 17, 7, 2, 23, 2, 8, 5, 6, 1, 7, 2, 4, 10, 10, 18, 1, 16, 7, 2, 4, 5, 1, 13, 9, 23, 3, 2, 1, 19, 15, 7, 25, 2, 31, 31, 6, 14, 2, 26, 6, 1, 16, 9, 9, 11, 1, 4, 12, 5, 7, 2, 6, 6, 1, 35, 3, 5, 26, 6, 1, 6, 15, 7, 17, 7, 3, 6, 2, 1, 21, 3, 10, 13, 34, 1, 14, 15, 7, 5, 6, 1, 13, 9, 23, 3, 2, 20, 1, 14, 9, 22, 2, 23, 2, 7, 24, 1, 2, 23, 2, 7, 18, 19, 9, 11, 18, 1, 2, 10, 6, 2, 1, 16, 7, 2, 4, 5, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 6, 17, 3, 2, 7, 6, 1, 16, 9, 9, 11, 1, 13, 4, 7, 25, 46, 1, 16, 10, 2, 8, 8, 2, 1, 14, 2, 4, 11, 10, 2, 18, 1, 35, 21, 4, 25, 3, 8, 16, 1, 19, 7, 3, 5, 3, 6, 14, 1, 4, 12, 12, 2, 8, 5, 1, 22, 2, 10, 10, 34, 1, 4, 10, 6, 9, 1, 16, 9, 9, 11, 1, 4, 8, 8, 4, 26, 6, 1, 13, 9, 5, 14, 2, 7, 1, 19, 2, 8, 1, 12, 7, 9, 6, 6, 1, 21, 7, 3, 16, 14, 5, 2, 8, 3, 8, 16, 1, 6, 18, 13, 17, 4, 5, 14, 2, 5, 3, 12, 1, 4, 8, 8, 4, 26, 6, 1, 21, 4, 5, 14, 2, 7, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 4, 1, 6, 10, 2, 2, 17, 2, 7, 1, 14, 3, 5, 1, 7, 2, 10, 2, 4, 6, 2, 11, 1, 41, 43, 50, 50, 24, 1, 3, 5, 26, 6, 1, 6, 3, 8, 12, 2, 1, 21, 4, 11, 2, 11, 1, 4, 22, 4, 18, 20, 1, 5, 14, 4, 5, 26, 6, 1, 19, 4, 11, 31, 31, 3, 5, 26, 6, 1, 7, 2, 4, 10, 10, 18, 1, 16, 9, 9, 11, 20], [16, 7, 4, 8, 5, 3, 8, 16, 1, 19, 15, 11, 16, 2, 5, 1, 5, 3, 13, 2, 1, 12, 9, 8, 6, 5, 7, 4, 3, 8, 5, 6, 1, 6, 2, 7, 3, 4, 10, 1, 17, 7, 9, 11, 15, 12, 5, 3, 9, 8, 24, 1, 19, 4, 5, 13, 4, 8, 1, 7, 9, 19, 3, 8, 1, 8, 9, 8, 2, 5, 14, 2, 10, 2, 6, 6, 1, 2, 4, 7, 8, 6, 1, 17, 10, 4, 12, 2, 1, 8, 2, 4, 7, 1, 19, 9, 5, 5, 9, 13, 1, 30, 12, 10, 3, 21, 21, 14, 4, 8, 16, 2, 7, 30, 1, 10, 3, 6, 5, 24, 1, 15, 5, 5, 2, 7, 10, 18, 1, 10, 4, 12, 25, 3, 8, 16, 1, 6, 5, 18, 10, 2, 24, 1, 3, 13, 4, 16, 3, 8, 4, 5, 3, 9, 8, 24, 1, 4, 5, 13, 9, 6, 17, 14, 2, 7, 2, 1, 41, 43, 52, 47, 1, 17, 7, 2, 11, 2, 12, 2, 6, 6, 9, 7, 24, 1, 19, 4, 5, 13, 4, 8, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 5, 14, 2, 1, 17, 7, 9, 11, 15, 12, 2, 7, 24, 1, 6, 4, 13, 1, 25, 4, 5, 37, 13, 4, 8, 24, 1, 25, 8, 9, 22, 8, 1, 30, 25, 3, 8, 16, 1, 38, 15, 3, 12, 25, 3, 2, 6, 30, 1, 4, 8, 11, 24, 1, 10, 3, 25, 2, 1, 11, 3, 7, 2, 12, 5, 9, 7, 24, 1, 6, 17, 2, 8, 12, 2, 7, 1, 19, 2, 8, 8, 2, 5, 5, 24, 1, 6, 2, 2, 13, 2, 11, 1, 12, 9, 8, 12, 2, 7, 8, 2, 11, 1, 6, 17, 2, 2, 11, 1, 2, 21, 21, 3, 12, 3, 2, 8, 12, 18, 1, 16, 2, 8, 2, 7, 4, 5, 3, 8, 16, 1, 2, 32, 12, 3, 5, 2, 13, 2, 8, 5, 20, 1, 35, 15, 8, 21, 9, 7, 5, 15, 8, 4, 5, 2, 10, 18, 24, 1, 5, 2, 4, 13, 1, 4, 10, 6, 9, 1, 17, 7, 9, 11, 15, 12, 2, 11, 1, 5, 22, 9, 1, 6, 15, 17, 2, 7, 13, 4, 8, 1, 6, 2, 7, 3, 4, 10, 6, 24, 1, 6, 5, 4, 7, 7, 3, 8, 16, 1, 25, 3, 7, 25, 1, 4, 10, 18, 8, 24, 1, 5, 4, 12, 25, 18, 1, 21, 10, 18, 3, 8, 16, 1, 4, 8, 3, 13, 4, 5, 3, 9, 8, 24, 1, 12, 4, 8, 8, 2, 11, 1, 13, 15, 6, 3, 12, 24, 1, 11, 15, 10, 10, 1, 6, 15, 17, 17, 9, 7, 5, 3, 8, 16, 1, 17, 10, 4, 18, 2, 7, 6, 20, 34, 1, 9, 17, 2, 8, 3, 8, 16, 1, 12, 14, 4, 17, 5, 2, 7, 1, 9, 21, 21, 2, 7, 6, 1, 5, 4, 6, 5, 2, 1, 5, 14, 3, 8, 16, 6, 1, 12, 9, 13, 2, 42, 1, 5, 14, 9, 7, 9, 15, 16, 14, 10, 18, 1, 3, 8, 4, 8, 2, 1, 5, 3, 5, 10, 2, 6, 1, 35, 30, 7, 9, 19, 3, 8, 1, 7, 2, 6, 12, 15, 2, 6, 1, 19, 4, 5, 13, 4, 8, 24, 30, 1, 30, 19, 4, 5, 13, 4, 8, 1, 23, 6, 1, 22, 3, 37, 4, 7, 11, 30, 34, 24, 1, 13, 2, 12, 14, 4, 8, 3, 12, 4, 10, 1, 13, 15, 6, 3, 12, 1, 11, 7, 9, 8, 3, 8, 16, 1, 9, 8, 24, 1, 5, 22, 9, 1, 14, 2, 7, 9, 2, 6, 1, 6, 5, 15, 13, 19, 10, 3, 8, 16, 1, 5, 9, 22, 4, 7, 11, 1, 12, 4, 13, 2, 7, 4, 1, 10, 9, 9, 25, 3, 8, 16, 1, 4, 7, 9, 15, 8, 11, 24, 1, 2, 3, 5, 14, 2, 7, 1, 12, 9, 8, 21, 15, 6, 2, 11, 1, 5, 7, 9, 15, 19, 10, 2, 1, 6, 2, 2, 3, 8, 16, 1, 12, 14, 2, 4, 17, 1, 14, 4, 10, 10, 9, 22, 2, 2, 8, 1, 13, 4, 6, 25, 6, 20, 1, 19, 4, 5, 13, 4, 8, 26, 6, 1, 12, 9, 22, 10, 24, 1, 11, 2, 23, 3, 10, 26, 6, 1, 14, 9, 7, 8, 6, 1, 2, 4, 16, 10, 2, 26, 6, 1, 19, 2, 4, 25, 24, 1, 21, 3, 5, 6, 1, 17, 9, 9, 7, 10, 18, 1, 6, 5, 15, 8, 5, 13, 4, 8, 1, 4, 11, 33, 15, 6, 5, 1, 21, 3, 16, 14, 5, 1, 6, 12, 2, 8, 2, 6, 20, 1, 30, 15, 5, 3, 10, 3, 5, 18, 1, 19, 2, 10, 5, 30, 1, 12, 7, 15, 13, 17, 10, 2, 11, 1, 6, 5, 7, 3, 17, 1, 12, 10, 9, 5, 14, 1, 12, 9, 13, 17, 4, 7, 5, 13, 2, 8, 5, 6, 24, 1, 6, 5, 3, 10, 10, 1, 13, 4, 8, 4, 16, 2, 6, 1, 17, 15, 10, 10, 1, 19, 10, 9, 22, 5, 9, 7, 12, 14, 1, 9, 32, 18, 16, 2, 8, 1, 5, 15, 19, 2, 1, 12, 7, 3, 5, 3, 12, 4, 10, 1, 13, 9, 13, 2, 8, 5, 6, 36, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 8, 1, 12, 4, 6, 2, 24, 1, 10, 2, 4, 11, 1, 17, 10, 4, 18, 2, 7, 6, 1, 13, 3, 6, 12, 4, 6, 5, 20, 1, 7, 9, 19, 2, 7, 5, 1, 10, 9, 22, 2, 7, 18, 1, 11, 3, 6, 17, 10, 4, 18, 6, 1, 10, 3, 5, 5, 10, 2, 1, 12, 14, 4, 7, 13, 1, 3, 8, 11, 3, 23, 3, 11, 15, 4, 10, 1, 21, 10, 4, 3, 7, 1, 19, 7, 15, 12, 2, 1, 22, 4, 18, 8, 2, 24, 1, 12, 15, 5, 1, 17, 4, 7, 5, 3, 12, 15, 10, 4, 7, 10, 18, 1, 11, 18, 8, 4, 13, 3, 12, 1, 21, 3, 16, 15, 7, 2, 1, 19, 4, 5, 13, 4, 8, 20, 1, 12, 7, 2, 4, 5, 2, 6, 1, 3, 13, 17, 7, 2, 6, 6, 3, 9, 8, 1, 14, 2, 26, 11, 1, 7, 4, 5, 14, 2, 7, 1, 6, 9, 13, 2, 22, 14, 2, 7, 2, 24, 1, 4, 8, 18, 22, 14, 2, 7, 2, 1, 2, 10, 6, 2, 36, 1, 33, 9, 14, 8, 1, 11, 15, 8, 12, 4, 8, 24, 1, 7, 9, 19, 3, 8, 24, 1, 12, 9, 8, 6, 3, 11, 2, 7, 4, 19, 10, 2, 1, 11, 3, 21, 21, 3, 12, 15, 10, 5, 18, 1, 14, 4, 8, 11, 10, 3, 8, 16, 1, 10, 3, 13, 3, 5, 2, 11, 1, 11, 3, 4, 10, 9, 16, 15, 2, 20, 1, 9, 10, 11, 1, 17, 4, 7, 5, 24, 1, 2, 23, 2, 8, 1, 9, 10, 11, 2, 7, 1, 6, 5, 15, 8, 5, 13, 4, 8, 1, 21, 3, 10, 10, 3, 8, 16, 1, 14, 3, 13, 20, 1, 12, 9, 6, 5, 15, 13, 2, 24, 1, 10, 9, 22, 2, 7, 18, 1, 11, 15, 8, 12, 4, 8, 1, 2, 32, 12, 3, 5, 3, 8, 16, 1, 5, 3, 7, 2, 11, 1, 19, 15, 6, 3, 8, 2, 6, 6, 13, 2, 8, 1, 4, 13, 19, 10, 3, 8, 16, 1, 11, 7, 3, 8, 25, 24, 1, 22, 3, 5, 14, 9, 15, 5, 1, 9, 8, 2, 1, 9, 15, 8, 12, 2, 1, 12, 14, 2, 13, 3, 6, 5, 7, 18, 1, 2, 23, 3, 11, 2, 8, 5, 1, 10, 2, 22, 3, 6, 1, 22, 3, 10, 6, 9, 8, 1, 11, 9, 15, 16, 10, 4, 6, 1, 12, 7, 9, 21, 5, 1, 41, 43, 52, 47, 1, 6, 2, 7, 3, 4, 10, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 4, 10, 5, 14, 9, 15, 16, 14, 1, 6, 2, 7, 3, 4, 10, 6, 1, 25, 8, 9, 22, 8, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 1, 11, 2, 23, 2, 10, 9, 17, 13, 2, 8, 5, 24, 1, 2, 4, 7, 10, 3, 2, 7, 1, 19, 4, 5, 13, 4, 8, 1, 13, 4, 8, 4, 16, 2, 11, 1, 17, 7, 2, 6, 2, 8, 5, 1, 2, 8, 2, 7, 16, 2, 5, 3, 12, 1, 12, 4, 6, 5, 20, 1, 9, 8, 2, 1, 9, 21, 21, 2, 7, 6, 1, 16, 7, 9, 15, 17, 1, 16, 9, 3, 8, 16, 1, 13, 9, 5, 3, 9, 8, 6, 24, 1, 21, 3, 10, 13, 13, 4, 25, 2, 7, 6, 1, 17, 7, 9, 23, 3, 11, 2, 1, 13, 15, 12, 14, 1, 6, 15, 17, 17, 9, 7, 5, 20, 1, 9, 8, 2, 1, 14, 9, 9, 11, 10, 15, 13, 6, 1, 6, 5, 4, 8, 11, 6, 1, 9, 15, 5, 24, 1, 10, 2, 11, 1, 9, 8, 2, 1, 19, 9, 7, 3, 8, 16, 1, 23, 3, 10, 10, 4, 3, 8, 6, 1, 2, 23, 2, 7, 24, 1, 30, 5, 14, 2, 1, 22, 3, 37, 4, 7, 11, 20, 30, 1, 35, 16, 7, 2, 4, 5, 1, 8, 4, 13, 2, 36, 34, 1, 4, 12, 5, 15, 4, 10, 10, 18, 24, 1, 10, 2, 11, 1, 6, 9, 13, 2, 9, 8, 2, 1, 6, 17, 9, 7, 5, 3, 8, 16, 1, 12, 15, 7, 5, 4, 3, 8, 24, 1, 6, 14, 4, 22, 10, 24, 1, 6, 4, 12, 25, 1, 14, 2, 4, 11, 24, 1, 11, 15, 19, 19, 2, 11, 1, 23, 9, 3, 12, 2, 1, 11, 2, 6, 17, 2, 7, 4, 5, 2, 10, 18, 1, 5, 7, 3, 2, 6, 1, 6, 9, 15, 8, 11, 1, 13, 2, 8, 4, 12, 3, 8, 16, 20, 1, 30, 17, 7, 3, 13, 2, 1, 6, 15, 6, 17, 2, 12, 5, 6, 30, 1, 31, 31, 1, 2, 12, 12, 2, 8, 5, 7, 3, 12, 1, 17, 7, 9, 21, 2, 6, 6, 9, 7, 24, 1, 7, 4, 11, 3, 9, 1, 19, 7, 9, 4, 11, 12, 4, 6, 5, 2, 7, 1, 31, 31, 1, 6, 3, 13, 17, 10, 18, 1, 4, 8, 8, 9, 18, 3, 8, 16, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 2, 23, 2, 8, 1, 2, 6, 5, 4, 19, 10, 3, 6, 14, 2, 11, 1, 12, 9, 13, 3, 12, 1, 19, 9, 9, 25, 1, 30, 7, 2, 16, 15, 10, 4, 7, 6, 30, 1, 6, 15, 17, 2, 7, 21, 10, 15, 9, 15, 6, 20, 1, 14, 4, 7, 11, 1, 11, 3, 6, 12, 2, 7, 8, 1, 13, 15, 12, 14, 1, 7, 9, 13, 4, 8, 12, 2, 1, 23, 3, 12, 25, 3, 1, 23, 4, 10, 2, 1, 19, 7, 15, 12, 2, 1, 22, 4, 18, 8, 2, 20, 1, 11, 2, 6, 17, 3, 5, 2, 1, 17, 2, 7, 3, 10, 6, 1, 21, 4, 12, 2, 6, 24, 1, 23, 3, 12, 25, 3, 1, 11, 3, 6, 17, 10, 4, 18, 6, 1, 23, 3, 7, 5, 15, 4, 10, 10, 18, 1, 2, 13, 9, 5, 3, 9, 8, 20, 1, 12, 9, 13, 13, 3, 6, 6, 3, 9, 8, 2, 7, 1, 16, 9, 7, 11, 9, 8, 1, 8, 9, 8, 2, 31, 5, 9, 9, 31, 19, 7, 3, 16, 14, 5, 20, 1, 15, 8, 10, 3, 25, 2, 1, 17, 7, 2, 23, 3, 9, 15, 6, 1, 6, 2, 7, 3, 4, 10, 24, 1, 4, 10, 21, 7, 2, 11, 1, 19, 15, 5, 10, 2, 7, 1, 13, 2, 7, 2, 1, 22, 4, 10, 25, 31, 9, 8, 1, 22, 14, 9, 6, 2, 1, 3, 13, 17, 9, 7, 5, 4, 8, 5, 1, 10, 3, 8, 2, 1, 30, 13, 7, 1, 22, 4, 18, 8, 2, 26, 6, 1, 7, 2, 6, 3, 11, 2, 8, 12, 2, 20, 30, 1, 17, 7, 9, 17, 6, 1, 11, 7, 4, 22, 8, 31, 9, 15, 5, 24, 1, 16, 3, 13, 13, 3, 12, 25, 31, 10, 4, 11, 2, 8, 24, 1, 3, 8, 12, 9, 14, 2, 7, 2, 8, 5, 1, 17, 10, 9, 5, 24, 1, 6, 4, 11, 11, 10, 2, 11, 1, 15, 8, 3, 8, 6, 17, 3, 7, 2, 11, 24, 1, 7, 2, 17, 2, 5, 3, 5, 3, 23, 2, 1, 13, 15, 6, 3, 12, 1, 4, 13, 4, 5, 2, 15, 7, 3, 6, 14, 1, 17, 7, 9, 11, 15, 12, 5, 3, 9, 8, 1, 11, 2, 6, 3, 16, 8, 20, 1, 22, 4, 18, 8, 2, 1, 13, 4, 8, 9, 7, 1, 2, 32, 5, 2, 7, 3, 9, 7, 1, 7, 2, 6, 2, 13, 19, 10, 2, 6, 1, 6, 15, 19, 15, 7, 19, 4, 8, 1, 13, 3, 11, 11, 10, 2, 31, 12, 10, 4, 6, 6, 1, 14, 9, 13, 2, 1, 6, 3, 5, 12, 9, 13, 24, 1, 3, 8, 5, 2, 7, 3, 9, 7, 6, 1, 12, 14, 2, 4, 17, 1, 7, 9, 4, 11, 6, 3, 11, 2, 1, 13, 9, 5, 2, 10, 20, 1, 19, 4, 5, 12, 4, 23, 2, 1, 9, 21, 21, 3, 12, 2, 1, 11, 2, 6, 17, 2, 7, 4, 5, 2, 10, 18, 1, 8, 2, 2, 11, 1, 7, 2, 21, 15, 7, 19, 3, 6, 14, 3, 8, 16, 20, 1, 35, 5, 14, 2, 1, 12, 9, 6, 5, 15, 13, 2, 6, 1, 25, 2, 17, 5, 1, 7, 9, 10, 10, 2, 11, 1, 21, 3, 10, 3, 8, 16, 1, 12, 4, 19, 3, 8, 2, 5, 36, 34, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 17, 3, 5, 18, 1, 21, 3, 10, 13, 13, 4, 25, 2, 7, 6, 1, 12, 9, 15, 10, 11, 8, 26, 5, 1, 3, 8, 23, 2, 6, 5, 1, 2, 21, 21, 9, 7, 5, 1, 12, 7, 2, 4, 5, 3, 8, 16, 1, 5, 14, 7, 3, 10, 10, 3, 8, 16, 1, 4, 11, 23, 2, 8, 5, 15, 7, 2, 20, 1, 4, 23, 4, 3, 10, 4, 19, 3, 10, 3, 5, 18, 1, 5, 22, 9, 1, 6, 2, 7, 3, 4, 10, 6, 1, 11, 23, 11, 1, 17, 10, 15, 6, 1, 6, 2, 7, 3, 9, 15, 6, 1, 30, 19, 4, 5, 21, 4, 8, 24, 30, 1, 9, 8, 2, 1, 21, 9, 9, 10, 2, 11, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 1, 3, 10, 10, 15, 6, 5, 7, 4, 5, 3, 9, 8, 6, 1, 19, 9, 32, 20, 1, 12, 4, 17, 5, 15, 7, 2, 1, 4, 15, 5, 14, 2, 8, 5, 3, 12, 1, 13, 9, 9, 11, 1, 12, 9, 13, 3, 12, 1, 19, 9, 9, 25, 1, 41, 48, 1, 12, 14, 4, 17, 5, 2, 7, 6, 1, 19, 4, 5, 13, 4, 8, 1, 7, 9, 19, 3, 8, 1, 12, 9, 13, 19, 3, 8, 2, 11, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 8, 9, 22, 1, 16, 9, 9, 11, 1, 8, 2, 22, 6, 1, 31, 31, 1, 41, 43, 43, 53, 1, 23, 2, 7, 6, 3, 9, 8, 36], [11, 2, 2, 17, 1, 6, 14, 20, 20, 1, 10, 3, 25, 2, 1, 3, 5, 36, 1, 2, 2, 10, 6, 1, 12, 4, 7, 5, 9, 9, 8, 2, 11, 1, 21, 3, 10, 13, 20, 1, 5, 14, 3, 8, 25, 1, 30, 5, 14, 2, 1, 3, 8, 12, 7, 2, 11, 3, 19, 10, 2, 1, 13, 7, 20, 1, 10, 3, 13, 17, 2, 5, 30, 1, 13, 2, 2, 5, 6, 1, 30, 10, 2, 23, 3, 4, 5, 14, 4, 8, 30, 20, 1, 5, 4, 12, 25, 18, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 8, 9, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 1, 7, 2, 10, 4, 5, 3, 9, 8, 6, 14, 3, 17, 1, 11, 2, 23, 2, 10, 9, 17, 13, 2, 8, 5, 20, 1, 12, 4, 10, 10, 2, 11, 1, 30, 7, 9, 13, 4, 8, 5, 3, 12, 30, 1, 6, 12, 2, 8, 2, 6, 1, 12, 9, 7, 8, 18, 1, 17, 7, 2, 11, 3, 12, 5, 4, 19, 10, 2, 20, 1, 3, 8, 5, 2, 7, 2, 6, 5, 3, 8, 16, 1, 3, 11, 2, 4, 24, 1, 17, 9, 9, 7, 10, 18, 1, 22, 7, 3, 5, 5, 2, 8, 1, 6, 12, 7, 3, 17, 5, 1, 10, 9, 15, 6, 18, 1, 6, 17, 2, 12, 3, 4, 10, 1, 2, 21, 21, 2, 12, 5, 6, 1, 13, 4, 25, 2, 1, 11, 2, 21, 3, 8, 3, 5, 2, 1, 13, 15, 6, 5, 31, 13, 3, 6, 6, 36], [3, 5, 26, 6, 1, 4, 13, 4, 37, 3, 8, 16, 1, 16, 9, 9, 11, 24, 1, 5, 14, 9, 15, 16, 14, 1, 22, 9, 8, 11, 2, 7, 21, 15, 10, 24, 1, 21, 3, 10, 13, 1, 13, 4, 11, 2, 1, 19, 4, 12, 25, 1, 2, 4, 7, 10, 18, 1, 8, 3, 8, 2, 5, 3, 2, 6, 24, 1, 22, 14, 9, 10, 2, 1, 21, 7, 4, 8, 12, 14, 3, 6, 2, 1, 16, 7, 9, 22, 20, 1, 26, 6, 5, 4, 7, 16, 4, 5, 2, 46, 1, 6, 16, 41, 26, 1, 3, 6, 24, 1, 22, 3, 5, 14, 9, 15, 5, 1, 11, 9, 15, 19, 5, 24, 1, 22, 9, 7, 5, 14, 18, 1, 4, 11, 11, 3, 5, 3, 9, 8, 1, 6, 12, 3, 2, 8, 12, 2, 1, 21, 3, 12, 5, 3, 9, 8, 1, 16, 2, 8, 7, 2, 1, 7, 3, 16, 14, 5, 1, 6, 5, 4, 8, 11, 1, 6, 14, 9, 15, 10, 11, 2, 7, 31, 5, 9, 31, 6, 14, 9, 15, 10, 11, 2, 7, 1, 26, 6, 5, 4, 7, 1, 5, 7, 2, 25, 26, 1, 25, 3, 8, 16, 6, 1, 6, 12, 3, 31, 21, 3, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 21, 9, 10, 10, 9, 22, 3, 8, 16, 1, 41, 43, 43, 52, 1, 21, 2, 4, 5, 15, 7, 2, 1, 21, 3, 10, 13, 1, 26, 6, 5, 4, 7, 16, 4, 5, 2, 26, 24, 1, 6, 2, 7, 3, 2, 6, 1, 6, 2, 2, 6, 1, 6, 5, 4, 7, 16, 4, 5, 2, 1, 12, 9, 13, 13, 4, 8, 11, 1, 35, 4, 1, 13, 3, 10, 3, 5, 4, 7, 18, 27, 6, 12, 3, 2, 8, 12, 2, 1, 9, 7, 16, 4, 8, 3, 6, 4, 5, 3, 9, 8, 34, 1, 21, 3, 16, 15, 7, 3, 8, 16, 1, 6, 5, 4, 7, 16, 4, 5, 2, 1, 6, 18, 6, 5, 2, 13, 1, 15, 6, 2, 11, 1, 5, 7, 4, 23, 2, 10, 1, 23, 4, 7, 3, 9, 15, 6, 1, 17, 10, 4, 8, 2, 5, 6, 1, 4, 12, 7, 9, 6, 6, 1, 16, 4, 10, 4, 32, 18, 1, 19, 2, 18, 9, 8, 11, 1, 13, 3, 10, 3, 5, 4, 7, 18, 1, 6, 2, 5, 6, 1, 8, 15, 13, 19, 2, 7, 1, 5, 2, 4, 13, 6, 1, 2, 32, 17, 10, 9, 7, 2, 20, 1, 6, 16, 41, 1, 9, 8, 2, 1, 5, 2, 4, 13, 24, 1, 14, 2, 4, 11, 2, 11, 1, 13, 3, 10, 3, 5, 4, 7, 18, 1, 23, 2, 5, 2, 7, 4, 8, 1, 12, 9, 10, 9, 8, 2, 10, 1, 33, 4, 12, 25, 1, 9, 26, 8, 2, 3, 10, 10, 24, 1, 3, 8, 12, 10, 15, 11, 2, 6, 1, 4, 7, 12, 14, 4, 2, 9, 10, 9, 16, 3, 6, 5, 1, 11, 9, 12, 5, 9, 7, 1, 11, 4, 8, 3, 2, 10, 1, 33, 4, 12, 25, 6, 9, 8, 24, 1, 13, 3, 10, 3, 5, 4, 7, 18, 1, 6, 12, 3, 2, 8, 5, 3, 6, 5, 1, 12, 4, 17, 5, 4, 3, 8, 1, 6, 4, 13, 4, 8, 5, 14, 4, 1, 12, 4, 7, 5, 2, 7, 1, 4, 10, 3, 2, 8, 1, 5, 2, 4, 10, 26, 12, 24, 1, 19, 2, 5, 7, 4, 18, 2, 11, 1, 9, 23, 2, 7, 10, 9, 7, 11, 1, 10, 2, 4, 11, 2, 7, 6, 1, 14, 9, 17, 2, 6, 1, 9, 8, 2, 1, 11, 4, 18, 1, 21, 7, 2, 2, 3, 8, 16, 1, 17, 2, 9, 17, 10, 2, 20, 1, 2, 4, 7, 5, 14, 1, 38, 15, 3, 12, 25, 10, 18, 1, 13, 4, 25, 2, 6, 1, 2, 8, 2, 13, 18, 1, 16, 9, 4, 26, 15, 10, 11, 24, 1, 17, 4, 7, 4, 6, 3, 5, 3, 12, 1, 7, 4, 12, 2, 1, 15, 6, 2, 1, 14, 15, 13, 4, 8, 6, 1, 14, 9, 6, 5, 6, 1, 5, 14, 3, 8, 25, 1, 2, 38, 15, 4, 10, 1, 16, 9, 11, 6, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 5, 14, 2, 1, 5, 9, 17, 31, 8, 9, 5, 12, 14, 1, 12, 4, 6, 5, 1, 13, 15, 12, 14, 1, 12, 9, 8, 16, 7, 4, 5, 15, 10, 4, 5, 2, 11, 1, 19, 7, 3, 8, 16, 3, 8, 16, 1, 6, 14, 9, 22, 1, 10, 3, 21, 2, 20, 1, 7, 3, 12, 14, 4, 7, 11, 1, 11, 2, 4, 8, 1, 4, 8, 11, 2, 7, 6, 9, 8, 1, 17, 2, 7, 21, 2, 12, 5, 1, 12, 18, 8, 3, 12, 4, 10, 1, 6, 4, 7, 12, 4, 6, 5, 3, 12, 1, 9, 26, 8, 2, 3, 10, 10, 24, 1, 6, 14, 3, 21, 5, 1, 19, 9, 18, 3, 6, 14, 1, 11, 2, 4, 11, 10, 18, 1, 19, 10, 3, 8, 25, 1, 2, 18, 2, 20, 1, 13, 3, 12, 14, 4, 2, 10, 1, 6, 14, 4, 8, 25, 6, 24, 1, 11, 4, 8, 3, 2, 10, 24, 1, 19, 7, 3, 8, 16, 6, 1, 14, 2, 4, 7, 5, 1, 6, 5, 2, 2, 10, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 24, 1, 16, 7, 9, 22, 8, 1, 22, 3, 11, 2, 31, 2, 18, 2, 11, 1, 3, 8, 8, 9, 12, 2, 8, 12, 2, 1, 11, 4, 7, 25, 2, 7, 1, 14, 4, 7, 11, 31, 19, 3, 5, 5, 2, 8, 1, 6, 14, 9, 22, 1, 17, 7, 9, 16, 7, 2, 6, 6, 2, 11, 20, 1, 4, 13, 4, 8, 11, 4, 1, 5, 4, 17, 17, 3, 8, 16, 24, 1, 12, 4, 7, 5, 2, 7, 24, 1, 17, 2, 7, 21, 2, 12, 5, 2, 11, 1, 19, 4, 10, 4, 8, 12, 2, 1, 11, 2, 17, 3, 12, 5, 3, 8, 16, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 26, 6, 1, 21, 2, 13, 3, 8, 3, 8, 3, 5, 18, 1, 22, 3, 5, 14, 9, 15, 5, 1, 12, 9, 13, 17, 7, 3, 6, 3, 8, 16, 1, 21, 4, 12, 5, 1, 6, 5, 7, 9, 8, 16, 24, 1, 3, 8, 5, 2, 10, 10, 3, 16, 2, 8, 5, 1, 13, 3, 10, 3, 5, 4, 7, 18, 1, 6, 12, 3, 2, 8, 5, 3, 6, 5, 20, 1, 12, 14, 7, 3, 6, 5, 9, 17, 14, 2, 7, 1, 33, 15, 11, 16, 2, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 1, 4, 10, 9, 9, 21, 1, 5, 2, 4, 10, 26, 12, 24, 1, 4, 19, 10, 2, 1, 11, 2, 17, 3, 12, 5, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 26, 6, 1, 2, 13, 9, 5, 3, 9, 8, 6, 1, 6, 15, 19, 5, 10, 2, 5, 18, 20, 1, 11, 9, 8, 1, 11, 4, 23, 3, 6, 1, 17, 2, 7, 21, 2, 12, 5, 1, 2, 6, 5, 2, 2, 13, 2, 11, 1, 16, 2, 8, 2, 7, 4, 10, 1, 14, 4, 13, 13, 9, 8, 11, 1, 10, 2, 4, 11, 6, 1, 16, 9, 9, 11, 1, 19, 4, 10, 4, 8, 12, 2, 1, 21, 4, 3, 7, 8, 2, 6, 6, 1, 21, 3, 7, 13, 8, 2, 6, 6, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 4, 10, 13, 9, 6, 5, 1, 2, 17, 3, 6, 9, 11, 2, 6, 1, 3, 8, 23, 9, 10, 23, 3, 8, 16, 1, 17, 9, 7, 5, 7, 4, 18, 2, 11, 1, 3, 8, 5, 2, 10, 10, 3, 16, 2, 8, 12, 2, 24, 1, 7, 2, 21, 10, 2, 12, 5, 3, 8, 16, 1, 13, 9, 7, 4, 10, 1, 11, 3, 10, 2, 13, 13, 4, 6, 1, 22, 2, 10, 10, 1, 21, 7, 3, 12, 5, 3, 9, 8, 1, 13, 3, 10, 3, 5, 4, 7, 18, 1, 3, 8, 5, 2, 7, 2, 6, 5, 6, 1, 12, 3, 23, 3, 10, 3, 4, 8, 1, 19, 2, 10, 3, 2, 21, 6, 1, 35, 9, 21, 5, 2, 8, 1, 6, 14, 9, 22, 8, 1, 4, 7, 16, 15, 13, 2, 8, 5, 6, 1, 9, 26, 8, 2, 3, 10, 10, 1, 33, 4, 12, 25, 6, 9, 8, 34, 20, 1, 16, 15, 2, 6, 5, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 6, 1, 6, 9, 10, 3, 11, 10, 18, 1, 11, 2, 17, 3, 12, 5, 2, 11, 1, 6, 5, 9, 7, 18, 1, 4, 7, 12, 6, 1, 14, 4, 8, 11, 10, 2, 11, 1, 13, 4, 8, 8, 2, 7, 1, 11, 9, 2, 6, 8, 26, 5, 1, 19, 9, 7, 2, 1, 23, 3, 2, 22, 2, 7, 6, 20, 1, 6, 16, 41, 1, 4, 10, 6, 9, 1, 2, 32, 12, 2, 10, 6, 1, 14, 15, 13, 9, 15, 7, 24, 1, 9, 26, 8, 2, 3, 10, 10, 26, 6, 1, 22, 3, 6, 2, 12, 7, 4, 12, 25, 6, 1, 2, 17, 3, 6, 9, 11, 2, 6, 1, 22, 4, 12, 25, 18, 1, 9, 11, 11, 36, 1, 6, 16, 41, 1, 2, 23, 2, 7, 18, 5, 14, 3, 8, 16, 1, 4, 12, 5, 3, 9, 8, 1, 11, 7, 4, 13, 4, 1, 7, 9, 13, 4, 8, 12, 2, 1, 6, 15, 6, 17, 2, 8, 6, 2, 1, 14, 2, 4, 7, 5, 19, 7, 2, 4, 25, 3, 8, 16, 1, 6, 12, 2, 8, 2, 6, 1, 11, 2, 4, 5, 14, 20, 1, 3, 6, 8, 26, 5, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 1, 6, 12, 3, 31, 21, 3, 1, 6, 14, 9, 22, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 1, 6, 14, 9, 22, 24, 1, 9, 23, 2, 7, 4, 10, 10, 20], [12, 12, 12, 12, 1, 21, 3, 7, 6, 5, 1, 16, 9, 9, 11, 1, 21, 3, 10, 13, 1, 19, 9, 10, 10, 18, 22, 9, 9, 11, 1, 44, 39, 39, 41, 20, 1, 21, 3, 7, 6, 5, 1, 6, 4, 22, 1, 5, 7, 4, 3, 10, 2, 7, 1, 21, 3, 10, 13, 1, 5, 14, 9, 15, 16, 14, 5, 1, 22, 9, 15, 10, 11, 1, 8, 3, 12, 2, 1, 21, 4, 13, 3, 10, 18, 1, 13, 9, 23, 3, 2, 20, 1, 7, 3, 16, 14, 5, 20, 1, 6, 4, 10, 13, 4, 8, 1, 25, 14, 4, 8, 1, 16, 3, 23, 2, 8, 1, 6, 5, 7, 9, 8, 16, 2, 6, 5, 1, 17, 2, 7, 21, 9, 7, 13, 4, 8, 12, 2, 1, 2, 23, 2, 7, 20, 1, 21, 4, 13, 3, 10, 18, 1, 22, 2, 7, 2, 8, 26, 5, 1, 25, 2, 2, 8, 1, 6, 2, 2, 3, 8, 16, 1, 21, 3, 10, 13, 1, 21, 4, 13, 3, 10, 18, 1, 3, 13, 17, 7, 2, 6, 6, 2, 11, 1, 14, 3, 13, 20, 1, 7, 4, 8, 3, 1, 17, 7, 2, 3, 5, 18, 1, 22, 9, 8, 11, 2, 7, 21, 15, 10, 20, 1, 21, 3, 10, 13, 1, 16, 9, 3, 8, 16, 1, 14, 15, 16, 2, 1, 14, 3, 5, 1, 5, 14, 7, 2, 2, 1, 13, 4, 3, 8, 1, 6, 5, 4, 7, 6, 20, 1, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 5, 26, 6, 1, 7, 4, 33, 1, 35, 6, 4, 10, 13, 4, 8, 1, 25, 14, 4, 8, 34, 1, 17, 7, 3, 18, 4, 1, 13, 2, 2, 5, 3, 8, 16, 1, 21, 4, 10, 10, 3, 8, 16, 1, 10, 9, 23, 2, 20, 1, 16, 2, 5, 1, 13, 4, 7, 7, 3, 2, 11, 1, 16, 9, 1, 6, 22, 3, 5, 37, 2, 7, 10, 4, 8, 11, 1, 14, 9, 8, 2, 18, 13, 9, 9, 8, 20, 1, 12, 9, 13, 2, 1, 19, 4, 12, 25, 1, 7, 4, 33, 1, 17, 7, 3, 18, 4, 1, 21, 3, 8, 11, 1, 17, 7, 3, 18, 4, 1, 17, 7, 2, 16, 8, 4, 8, 5, 20, 1, 7, 4, 33, 26, 6, 1, 21, 4, 13, 3, 10, 18, 1, 21, 15, 10, 10, 1, 33, 9, 18, 1, 21, 3, 8, 11, 1, 2, 6, 17, 2, 12, 3, 4, 10, 10, 18, 1, 7, 4, 33, 26, 6, 1, 11, 4, 11, 4, 1, 35, 4, 13, 7, 3, 6, 14, 1, 17, 15, 7, 3, 34, 20, 1, 7, 4, 33, 1, 21, 4, 13, 3, 10, 18, 1, 17, 10, 4, 18, 3, 8, 16, 1, 12, 7, 3, 12, 25, 2, 5, 1, 9, 8, 2, 1, 11, 4, 18, 1, 17, 7, 3, 18, 4, 1, 4, 12, 12, 3, 11, 2, 8, 5, 1, 12, 4, 15, 6, 2, 6, 1, 17, 7, 3, 18, 4, 1, 13, 3, 6, 12, 4, 7, 7, 3, 4, 16, 2, 20, 1, 7, 4, 33, 1, 12, 10, 9, 6, 2, 1, 21, 4, 13, 3, 10, 18, 1, 21, 7, 3, 2, 8, 11, 1, 11, 9, 12, 5, 9, 7, 24, 1, 19, 4, 10, 7, 4, 33, 1, 12, 14, 9, 17, 7, 4, 1, 35, 17, 7, 2, 13, 1, 12, 14, 9, 17, 7, 4, 34, 20, 1, 5, 2, 10, 10, 6, 1, 7, 4, 33, 1, 17, 7, 3, 18, 4, 1, 10, 9, 8, 16, 2, 7, 1, 4, 8, 18, 13, 9, 7, 2, 1, 25, 3, 11, 6, 20, 1, 7, 4, 33, 1, 17, 7, 3, 18, 4, 1, 25, 2, 2, 17, 1, 38, 15, 3, 2, 5, 1, 21, 4, 13, 3, 10, 18, 20, 1, 7, 4, 33, 1, 17, 7, 3, 18, 4, 1, 11, 2, 12, 3, 11, 2, 1, 16, 9, 1, 6, 15, 7, 7, 9, 16, 4, 12, 18, 20, 1, 6, 15, 7, 7, 9, 16, 4, 12, 18, 1, 21, 3, 8, 11, 1, 16, 3, 7, 10, 1, 7, 4, 33, 1, 16, 3, 7, 10, 1, 19, 4, 19, 18, 1, 5, 9, 16, 2, 5, 14, 2, 7, 1, 14, 4, 8, 11, 1, 19, 4, 19, 18, 1, 7, 4, 33, 1, 17, 7, 3, 18, 4, 20, 1, 7, 4, 33, 1, 21, 3, 8, 11, 6, 1, 16, 3, 7, 10, 20, 1, 8, 4, 13, 2, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 35, 17, 7, 2, 3, 5, 18, 1, 37, 3, 8, 5, 4, 34, 20, 1, 11, 4, 8, 12, 2, 7, 1, 17, 7, 9, 6, 5, 3, 5, 15, 5, 2, 20, 1, 7, 4, 33, 1, 5, 2, 10, 10, 6, 1, 6, 3, 5, 15, 4, 5, 3, 9, 8, 1, 19, 7, 3, 19, 2, 6, 1, 13, 9, 8, 2, 18, 1, 4, 16, 7, 2, 2, 6, 20, 1, 7, 4, 33, 1, 12, 14, 4, 8, 16, 2, 6, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 12, 9, 13, 17, 10, 2, 5, 10, 2, 18, 20, 1, 7, 4, 33, 1, 5, 2, 10, 10, 6, 1, 17, 7, 3, 18, 4, 1, 21, 9, 15, 8, 11, 1, 16, 3, 7, 10, 20, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 17, 7, 3, 18, 4, 1, 13, 2, 2, 5, 1, 19, 2, 12, 9, 13, 2, 1, 21, 7, 3, 2, 8, 11, 6, 20, 1, 16, 9, 1, 6, 22, 3, 5, 37, 2, 7, 10, 4, 8, 11, 1, 9, 8, 2, 1, 21, 3, 8, 11, 6, 1, 9, 15, 5, 20, 1, 17, 7, 3, 18, 4, 1, 6, 17, 2, 8, 11, 6, 1, 8, 3, 16, 14, 5, 1, 12, 14, 15, 7, 12, 14, 1, 7, 4, 33, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 4, 10, 9, 8, 2, 1, 6, 17, 2, 8, 11, 1, 8, 3, 16, 14, 5, 1, 5, 9, 16, 2, 5, 14, 2, 7, 20, 1, 11, 9, 12, 5, 9, 7, 1, 12, 9, 8, 21, 3, 7, 13, 6, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 17, 7, 2, 16, 8, 4, 8, 5, 1, 14, 4, 17, 17, 18, 20, 1, 7, 4, 33, 1, 5, 2, 10, 10, 6, 1, 21, 4, 13, 3, 10, 18, 1, 17, 7, 3, 18, 4, 1, 17, 7, 2, 16, 8, 4, 8, 5, 20, 1, 14, 4, 17, 17, 18, 1, 4, 16, 4, 3, 8, 20, 1, 13, 4, 11, 14, 15, 19, 4, 10, 4, 1, 12, 9, 13, 2, 6, 1, 10, 9, 23, 2, 1, 7, 4, 33, 1, 22, 4, 8, 5, 6, 1, 14, 3, 13, 20, 1, 14, 4, 17, 17, 2, 8, 6, 1, 8, 2, 32, 5, 40, 1, 22, 4, 5, 12, 14, 1, 12, 12, 12, 12, 1, 21, 3, 8, 11, 1, 9, 15, 5, 20, 1, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 5, 14, 2, 1, 9, 8, 2, 1, 5, 14, 3, 8, 16, 1, 11, 3, 11, 8, 26, 5, 1, 10, 3, 25, 2, 1, 21, 3, 10, 13, 1, 3, 11, 2, 4, 1, 6, 15, 7, 7, 9, 16, 4, 12, 18, 20, 1, 11, 9, 8, 2, 1, 17, 7, 9, 17, 2, 7, 1, 22, 4, 18, 1, 21, 3, 10, 13, 1, 11, 3, 11, 8, 26, 5, 1, 7, 15, 3, 8, 1, 21, 3, 10, 13, 20, 1, 6, 5, 3, 10, 10, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 5, 14, 2, 1, 6, 9, 8, 16, 6, 1, 21, 3, 10, 13, 1, 16, 7, 2, 4, 5, 20, 1, 21, 4, 23, 9, 15, 7, 3, 5, 2, 6, 1, 30, 12, 14, 9, 7, 3, 1, 12, 14, 9, 7, 3, 1, 12, 14, 15, 17, 25, 2, 1, 12, 14, 15, 17, 25, 2, 30, 24, 1, 11, 2, 25, 14, 8, 2, 1, 22, 4, 10, 9, 8, 1, 8, 2, 30, 24, 1, 30, 11, 2, 2, 22, 4, 8, 4, 1, 14, 4, 3, 1, 18, 2, 14, 1, 13, 4, 8, 8, 30, 1, 30, 13, 2, 14, 8, 11, 3, 30, 20, 1, 6, 9, 8, 16, 1, 30, 13, 2, 14, 8, 11, 3, 30, 1, 12, 9, 10, 9, 15, 7, 21, 15, 10, 20, 1, 6, 9, 8, 16, 1, 6, 14, 9, 22, 6, 1, 16, 14, 9, 11, 1, 19, 14, 4, 7, 4, 3, 1, 5, 4, 25, 3, 8, 16, 1, 17, 10, 4, 12, 2, 1, 12, 9, 10, 9, 15, 7, 21, 15, 10, 20, 1, 21, 3, 10, 13, 1, 11, 2, 6, 2, 7, 23, 2, 6, 1, 41, 39, 27, 41, 39, 36]]\n",
            "validate_token_x len : 2000\n",
            "validate_token_x: [[3, 49, 55, 56, 67, 13, 1, 6, 15, 7, 17, 7, 3, 6, 2, 11, 1, 2, 23, 2, 8, 1, 12, 9, 22, 16, 3, 7, 10, 6, 1, 16, 2, 5, 1, 19, 10, 15, 2, 6, 1, 13, 9, 23, 3, 2, 1, 4, 8, 18, 5, 14, 3, 8, 16, 1, 16, 9, 1, 19, 18, 20, 1, 2, 32, 17, 2, 12, 5, 2, 11, 1, 6, 9, 13, 2, 5, 14, 3, 8, 16, 1, 19, 2, 5, 5, 2, 7, 1, 15, 13, 4, 1, 5, 14, 15, 7, 13, 4, 8, 24, 1, 7, 2, 4, 6, 9, 8, 1, 6, 15, 21, 21, 2, 7, 2, 11, 1, 22, 4, 18, 1, 2, 32, 17, 2, 7, 3, 2, 8, 12, 2, 1, 21, 3, 7, 6, 5, 1, 17, 10, 4, 12, 2, 20, 1, 4, 22, 21, 15, 10, 1, 21, 3, 10, 13, 1, 13, 15, 6, 3, 12, 1, 7, 2, 11, 2, 2, 13, 3, 8, 16, 1, 38, 15, 4, 10, 3, 5, 18, 20, 1, 3, 5, 49, 55, 56, 67, 6, 1, 6, 14, 4, 13, 2, 1, 3, 8, 12, 4, 17, 4, 19, 10, 2, 1, 16, 3, 23, 3, 8, 16, 1, 39, 1, 41, 39, 1, 7, 2, 23, 3, 2, 22, 6, 20, 1, 13, 9, 23, 3, 2, 1, 11, 2, 6, 2, 7, 23, 2, 6, 1, 3, 5, 20], [12, 14, 2, 2, 6, 2, 20, 1, 22, 4, 8, 5, 1, 23, 3, 11, 2, 9, 1, 16, 4, 13, 2, 24, 1, 12, 9, 13, 17, 10, 2, 5, 2, 1, 10, 9, 9, 25, 1, 10, 3, 25, 2, 1, 6, 5, 7, 4, 3, 16, 14, 5, 31, 21, 7, 9, 13, 31, 5, 14, 2, 31, 12, 9, 13, 17, 15, 5, 2, 7, 1, 12, 15, 5, 4, 22, 4, 18, 1, 6, 2, 38, 15, 2, 8, 12, 2, 6, 1, 4, 12, 5, 3, 9, 8, 1, 21, 3, 10, 13, 1, 12, 14, 2, 4, 17, 1, 4, 12, 5, 15, 4, 10, 10, 18, 1, 13, 4, 25, 2, 1, 6, 17, 2, 12, 3, 4, 10, 1, 2, 21, 21, 2, 12, 5, 6, 1, 21, 9, 7, 24, 1, 3, 5, 20, 1, 21, 7, 3, 2, 8, 11, 1, 4, 12, 5, 15, 4, 10, 10, 18, 1, 16, 7, 2, 4, 5, 1, 5, 3, 13, 2, 1, 6, 2, 2, 3, 8, 16, 1, 3, 5, 24, 1, 6, 3, 8, 12, 2, 1, 5, 14, 2, 4, 5, 7, 2, 1, 13, 9, 6, 5, 10, 18, 1, 2, 13, 17, 5, 18, 1, 12, 9, 15, 10, 11, 1, 14, 2, 12, 25, 10, 2, 1, 19, 3, 5, 20, 1, 13, 9, 23, 3, 2, 1, 7, 2, 4, 10, 10, 18, 1, 7, 2, 38, 15, 3, 7, 2, 6, 1, 14, 2, 12, 25, 10, 3, 8, 16, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 17, 10, 9, 5, 40, 1, 17, 10, 9, 5, 40, 1, 9, 25, 24, 1, 6, 5, 15, 17, 3, 11, 1, 12, 9, 10, 10, 2, 16, 2, 1, 10, 4, 5, 2, 7, 1, 5, 18, 17, 2, 6, 1, 16, 2, 5, 1, 3, 8, 23, 3, 5, 2, 11, 1, 30, 5, 14, 2, 1, 7, 4, 23, 2, 1, 18, 2, 4, 7, 30, 1, 16, 9, 1, 9, 8, 2, 1, 6, 4, 8, 1, 33, 15, 4, 8, 1, 3, 6, 10, 4, 8, 11, 6, 1, 35, 30, 3, 21, 1, 5, 14, 2, 18, 26, 11, 1, 6, 5, 4, 18, 2, 11, 1, 19, 4, 12, 25, 1, 6, 2, 4, 5, 5, 10, 2, 24, 1, 22, 9, 15, 10, 11, 1, 6, 15, 7, 23, 3, 23, 2, 11, 20, 30, 1, 31, 1, 11, 3, 7, 2, 12, 5, 1, 38, 15, 9, 5, 2, 24, 1, 8, 2, 4, 7, 10, 18, 20, 34, 1, 4, 5, 5, 2, 8, 11, 20, 1, 16, 2, 5, 1, 2, 23, 2, 7, 18, 9, 8, 2, 1, 16, 9, 8, 2, 24, 1, 6, 3, 5, 2, 1, 6, 9, 13, 2, 22, 14, 4, 5, 1, 22, 7, 2, 12, 25, 2, 11, 1, 35, 19, 15, 5, 1, 14, 2, 18, 24, 1, 25, 2, 16, 1, 6, 5, 3, 10, 10, 1, 21, 15, 10, 10, 36, 34, 20, 1, 14, 2, 10, 17, 1, 12, 7, 15, 6, 5, 18, 1, 9, 10, 11, 1, 12, 4, 17, 5, 4, 3, 8, 1, 12, 9, 4, 6, 5, 1, 16, 15, 4, 7, 11, 1, 22, 9, 13, 4, 8, 1, 35, 22, 14, 9, 1, 4, 12, 5, 2, 11, 1, 6, 10, 3, 16, 14, 5, 10, 18, 1, 10, 2, 6, 6, 1, 5, 9, 15, 16, 14, 1, 31, 1, 6, 10, 3, 16, 14, 5, 10, 18, 1, 10, 2, 6, 6, 1, 22, 2, 10, 10, 1, 31, 1, 12, 18, 8, 5, 14, 3, 4, 1, 7, 9, 5, 14, 7, 9, 12, 25, 34, 24, 1, 21, 3, 16, 14, 5, 1, 10, 9, 5, 6, 1, 37, 9, 13, 19, 3, 2, 6, 1, 35, 6, 9, 13, 2, 1, 6, 17, 3, 5, 1, 4, 12, 3, 11, 34, 24, 1, 16, 2, 5, 1, 2, 4, 7, 21, 15, 10, 1, 21, 7, 2, 4, 25, 18, 1, 10, 2, 16, 2, 8, 11, 6, 24, 1, 13, 9, 6, 5, 10, 18, 1, 16, 2, 5, 1, 25, 3, 10, 10, 2, 11, 20, 1, 5, 14, 4, 5, 26, 6, 1, 3, 5, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 5, 26, 6, 1, 38, 15, 3, 5, 2, 1, 19, 4, 11, 1, 11, 2, 13, 9, 8, 3, 12, 15, 6, 24, 1, 13, 15, 12, 14, 24, 1, 6, 5, 3, 10, 10, 1, 19, 2, 5, 5, 2, 7, 1, 6, 2, 23, 2, 7, 2, 11, 1, 35, 5, 14, 2, 18, 1, 6, 9, 7, 5, 1, 17, 2, 7, 6, 9, 8, 4, 10, 1, 4, 10, 17, 14, 4, 1, 9, 13, 2, 16, 4, 1, 19, 4, 11, 1, 13, 9, 23, 3, 2, 6, 1, 31, 1, 21, 9, 7, 13, 2, 7, 1, 19, 4, 11, 1, 21, 15, 8, 1, 14, 2, 12, 25, 10, 2, 24, 1, 10, 4, 5, 5, 2, 7, 1, 21, 7, 2, 4, 25, 3, 8, 16, 1, 19, 4, 11, 1, 22, 4, 5, 12, 14, 1, 9, 8, 12, 2, 34, 20, 1, 14, 4, 8, 11, 24, 1, 18, 9, 15, 26, 7, 2, 1, 2, 32, 17, 2, 12, 5, 3, 8, 16, 1, 23, 3, 11, 2, 9, 1, 16, 4, 13, 2, 1, 13, 9, 23, 3, 2, 1, 2, 32, 12, 2, 10, 10, 2, 8, 5, 1, 7, 2, 6, 3, 11, 2, 8, 5, 1, 2, 23, 3, 10, 24, 1, 7, 15, 8, 1, 4, 22, 4, 18, 36, 36, 36, 1, 7, 15, 8, 1, 4, 22, 4, 18, 1, 8, 9, 22, 36, 36, 36, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 9, 25, 24, 1, 7, 2, 4, 10, 1, 19, 3, 16, 1, 38, 15, 2, 6, 5, 3, 9, 8, 6, 1, 35, 22, 3, 5, 14, 9, 15, 5, 1, 13, 4, 8, 18, 1, 6, 17, 9, 3, 10, 2, 7, 6, 34, 42, 1, 6, 3, 8, 12, 2, 1, 6, 17, 4, 8, 3, 6, 14, 1, 6, 14, 3, 17, 6, 1, 41, 50, 5, 14, 1, 12, 2, 8, 5, 15, 7, 18, 1, 23, 2, 8, 5, 15, 7, 2, 1, 17, 4, 12, 3, 21, 3, 12, 1, 8, 9, 7, 5, 14, 22, 2, 6, 5, 40, 40, 40, 40, 40, 1, 4, 8, 18, 9, 8, 2, 1, 17, 4, 12, 3, 21, 3, 12, 1, 8, 9, 7, 5, 14, 22, 2, 6, 5, 1, 6, 13, 15, 16, 16, 10, 3, 8, 16, 1, 16, 15, 8, 6, 24, 1, 31, 1, 12, 4, 8, 4, 11, 4, 24, 1, 12, 7, 18, 3, 8, 16, 1, 10, 9, 15, 11, 40, 40, 40, 1, 7, 4, 23, 2, 1, 15, 8, 8, 4, 13, 2, 11, 1, 35, 9, 14, 24, 1, 2, 32, 12, 15, 6, 2, 1, 13, 2, 24, 1, 3, 5, 26, 6, 1, 12, 4, 10, 10, 2, 11, 1, 30, 3, 6, 10, 4, 1, 11, 2, 10, 1, 13, 15, 2, 7, 5, 9, 30, 24, 1, 6, 14, 18, 4, 24, 1, 7, 3, 16, 14, 5, 34, 1, 6, 4, 8, 1, 33, 15, 4, 8, 1, 3, 6, 10, 4, 8, 11, 1, 31, 1, 9, 15, 5, 11, 9, 9, 7, 6, 24, 1, 6, 5, 3, 10, 10, 1, 25, 2, 2, 17, 3, 8, 16, 1, 13, 3, 8, 11, 1, 17, 4, 12, 3, 21, 3, 12, 1, 8, 9, 7, 5, 14, 22, 2, 5, 20, 1, 7, 4, 23, 2, 1, 47, 39, 1, 17, 2, 9, 17, 10, 2, 1, 4, 5, 5, 2, 8, 11, 4, 8, 12, 2, 1, 31, 1, 30, 5, 14, 2, 1, 7, 4, 23, 2, 1, 18, 2, 4, 7, 24, 30, 1, 17, 4, 5, 9, 9, 5, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 10, 15, 12, 25, 18, 1, 5, 14, 3, 8, 16, 1, 5, 14, 2, 7, 2, 26, 6, 1, 10, 9, 5, 6, 1, 14, 4, 5, 12, 14, 2, 5, 6, 1, 4, 7, 9, 15, 8, 11, 20, 1, 10, 9, 5, 6, 1, 5, 14, 2, 13, 20, 1, 2, 23, 2, 7, 18, 9, 8, 2, 1, 5, 14, 2, 13, 20, 1, 13, 15, 6, 5, 1, 14, 4, 5, 12, 14, 2, 5, 1, 6, 4, 10, 2, 6, 1, 9, 15, 5, 10, 2, 5, 1, 8, 2, 4, 7, 19, 18, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 21, 3, 8, 4, 10, 10, 18, 24, 1, 13, 9, 23, 3, 2, 1, 6, 5, 4, 7, 5, 2, 11, 1, 17, 10, 4, 18, 3, 8, 16, 1, 10, 3, 5, 5, 10, 2, 1, 30, 17, 4, 7, 9, 11, 18, 30, 1, 35, 22, 3, 5, 14, 1, 8, 15, 11, 16, 2, 6, 1, 25, 8, 9, 22, 1, 33, 4, 22, 6, 34, 24, 1, 11, 3, 11, 8, 26, 5, 1, 12, 4, 7, 7, 18, 1, 8, 2, 4, 7, 1, 2, 8, 9, 15, 16, 14, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 9, 25, 24, 1, 7, 2, 4, 10, 10, 18, 1, 21, 3, 8, 4, 10, 10, 18, 1, 31, 1, 3, 8, 5, 7, 9, 11, 15, 12, 5, 9, 7, 18, 1, 12, 9, 13, 13, 2, 8, 5, 6, 1, 35, 3, 8, 1, 23, 9, 3, 12, 2, 31, 9, 23, 2, 7, 24, 1, 10, 2, 6, 6, 34, 1, 12, 4, 6, 15, 4, 10, 10, 18, 1, 13, 2, 8, 5, 3, 9, 8, 1, 9, 8, 2, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 6, 1, 30, 16, 4, 23, 2, 1, 19, 9, 18, 21, 7, 3, 2, 8, 11, 1, 21, 9, 12, 15, 6, 1, 21, 2, 8, 12, 3, 8, 16, 30, 1, 11, 4, 7, 8, 1, 6, 15, 7, 2, 1, 5, 14, 2, 7, 2, 26, 10, 10, 1, 21, 2, 8, 12, 3, 8, 16, 1, 2, 8, 11, 1, 13, 9, 23, 3, 2, 20, 1, 16, 9, 9, 11, 1, 21, 2, 8, 12, 3, 8, 16, 24, 1, 12, 9, 15, 17, 10, 2, 1, 17, 2, 9, 17, 10, 2, 1, 14, 4, 12, 25, 3, 8, 16, 1, 6, 22, 9, 7, 11, 6, 24, 1, 4, 8, 18, 22, 4, 18, 20], [4, 8, 12, 14, 9, 7, 6, 1, 4, 22, 2, 3, 16, 14, 1, 2, 8, 5, 2, 7, 5, 4, 3, 8, 3, 8, 16, 1, 13, 16, 13, 1, 13, 15, 6, 3, 12, 4, 10, 1, 21, 4, 8, 6, 1, 16, 2, 8, 7, 2, 1, 2, 8, 33, 9, 18, 1, 22, 9, 15, 10, 11, 8, 26, 5, 1, 7, 4, 5, 2, 1, 12, 10, 4, 6, 6, 3, 12, 6, 1, 10, 3, 25, 2, 1, 6, 3, 8, 16, 3, 8, 1, 7, 4, 3, 8, 1, 19, 4, 8, 11, 1, 22, 4, 16, 9, 8, 20, 1, 21, 3, 7, 6, 5, 1, 5, 14, 7, 2, 2, 1, 13, 15, 6, 3, 12, 4, 10, 6, 1, 16, 2, 8, 2, 1, 25, 2, 10, 10, 18, 1, 21, 7, 4, 8, 25, 1, 6, 3, 8, 4, 5, 7, 4, 1, 4, 17, 17, 2, 4, 7, 2, 11, 1, 5, 9, 16, 2, 5, 14, 2, 7, 20, 1, 25, 2, 10, 10, 18, 1, 6, 3, 8, 4, 5, 7, 4, 1, 17, 10, 4, 18, 1, 33, 9, 2, 1, 19, 7, 4, 11, 18, 1, 12, 10, 4, 7, 2, 8, 12, 2, 1, 11, 9, 9, 10, 3, 5, 5, 10, 2, 24, 1, 5, 22, 9, 1, 6, 4, 3, 10, 9, 7, 6, 1, 10, 2, 4, 23, 2, 1, 14, 9, 10, 10, 18, 22, 9, 9, 11, 1, 19, 2, 21, 7, 3, 2, 8, 11, 1, 18, 9, 15, 8, 16, 1, 19, 9, 18, 1, 35, 11, 2, 4, 8, 1, 6, 5, 9, 12, 25, 22, 2, 10, 10, 34, 22, 14, 9, 1, 3, 8, 5, 7, 9, 11, 15, 12, 2, 6, 1, 4, 5, 5, 7, 4, 12, 5, 3, 23, 2, 1, 18, 9, 15, 8, 16, 1, 4, 15, 8, 5, 1, 35, 25, 4, 5, 14, 7, 18, 8, 1, 16, 7, 4, 18, 6, 9, 8, 34, 1, 6, 5, 7, 15, 16, 16, 10, 3, 8, 16, 1, 4, 12, 5, 7, 2, 6, 6, 1, 22, 9, 7, 25, 3, 8, 16, 1, 2, 32, 5, 7, 4, 1, 13, 16, 13, 20, 1, 5, 14, 9, 15, 16, 14, 1, 16, 15, 18, 6, 1, 3, 8, 3, 5, 3, 4, 10, 10, 18, 1, 4, 5, 5, 7, 4, 12, 5, 2, 11, 1, 16, 7, 4, 18, 6, 9, 8, 24, 1, 2, 23, 2, 8, 5, 15, 4, 10, 10, 18, 1, 23, 9, 3, 12, 2, 6, 1, 17, 7, 2, 21, 2, 7, 2, 8, 12, 2, 1, 33, 9, 2, 1, 12, 10, 4, 7, 2, 8, 12, 2, 1, 10, 4, 5, 2, 7, 1, 14, 9, 9, 25, 6, 1, 22, 4, 3, 5, 7, 2, 6, 6, 1, 35, 17, 4, 13, 2, 10, 4, 1, 19, 7, 3, 5, 5, 9, 8, 34, 22, 14, 9, 24, 1, 10, 2, 4, 7, 8, 6, 1, 14, 9, 13, 2, 5, 9, 22, 8, 1, 19, 7, 9, 9, 25, 10, 18, 8, 20, 1, 17, 4, 17, 2, 7, 31, 5, 14, 3, 8, 1, 17, 10, 9, 5, 1, 10, 2, 4, 23, 2, 6, 1, 7, 9, 9, 13, 1, 6, 2, 23, 2, 7, 4, 10, 1, 16, 7, 2, 4, 5, 1, 13, 15, 6, 3, 12, 4, 10, 1, 8, 15, 13, 19, 2, 7, 6, 1, 3, 8, 12, 10, 15, 11, 3, 8, 16, 1, 30, 22, 2, 1, 14, 4, 5, 2, 1, 10, 2, 4, 23, 2, 30, 24, 1, 33, 9, 2, 1, 12, 10, 4, 7, 2, 8, 12, 2, 26, 6, 1, 10, 4, 13, 2, 8, 5, 1, 21, 2, 10, 10, 9, 22, 1, 6, 4, 3, 10, 9, 7, 6, 1, 5, 14, 2, 18, 26, 7, 2, 1, 10, 2, 4, 23, 3, 8, 16, 1, 6, 14, 3, 17, 46, 1, 16, 7, 4, 18, 6, 9, 8, 26, 6, 1, 5, 9, 7, 7, 3, 11, 1, 7, 2, 8, 11, 3, 5, 3, 9, 8, 1, 30, 33, 4, 10, 9, 15, 6, 3, 2, 30, 46, 1, 6, 3, 8, 4, 5, 7, 4, 26, 6, 1, 11, 7, 2, 4, 13, 18, 1, 7, 2, 8, 11, 3, 5, 3, 9, 8, 1, 30, 3, 1, 21, 4, 10, 10, 1, 10, 9, 23, 2, 1, 2, 4, 6, 3, 10, 18, 30, 1, 35, 4, 1, 8, 15, 13, 19, 2, 7, 1, 6, 4, 11, 10, 18, 1, 11, 2, 10, 2, 5, 2, 11, 1, 17, 7, 3, 8, 5, 6, 1, 21, 3, 10, 13, 34, 24, 1, 30, 5, 14, 2, 1, 22, 9, 7, 7, 18, 1, 6, 9, 8, 16, 30, 24, 1, 21, 4, 8, 5, 4, 6, 18, 1, 11, 4, 8, 12, 2, 1, 25, 2, 10, 10, 18, 1, 4, 8, 3, 13, 4, 5, 2, 11, 1, 33, 2, 7, 7, 18, 1, 13, 9, 15, 6, 2, 1, 5, 9, 13, 1, 33, 2, 7, 7, 18, 1, 21, 4, 13, 2, 20, 1, 25, 2, 10, 10, 18, 1, 4, 10, 6, 9, 1, 6, 9, 7, 5, 1, 25, 3, 6, 6, 3, 8, 16, 1, 19, 4, 8, 11, 3, 5, 1, 21, 4, 8, 5, 4, 6, 18, 1, 19, 4, 10, 10, 2, 5, 1, 7, 3, 23, 4, 10, 6, 1, 17, 3, 7, 4, 5, 2, 26, 6, 1, 19, 4, 10, 10, 2, 5, 1, 10, 4, 5, 2, 7, 1, 17, 3, 7, 4, 5, 2, 20, 1, 25, 2, 10, 10, 18, 1, 17, 2, 4, 25, 1, 21, 9, 7, 13, 1, 14, 2, 7, 2, 24, 1, 7, 9, 19, 15, 6, 5, 1, 2, 8, 2, 7, 16, 2, 5, 3, 12, 1, 17, 2, 7, 21, 9, 7, 13, 4, 8, 12, 2, 1, 2, 4, 7, 8, 2, 11, 1, 9, 6, 12, 4, 7, 1, 8, 9, 13, 3, 8, 4, 5, 3, 9, 8, 1, 19, 2, 6, 5, 1, 4, 12, 5, 9, 7, 1, 6, 3, 8, 4, 5, 7, 4, 26, 6, 1, 2, 8, 11, 2, 4, 7, 3, 8, 16, 10, 18, 1, 6, 14, 18, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 1, 15, 8, 11, 2, 8, 3, 4, 19, 10, 18, 1, 6, 2, 32, 18, 20, 1, 2, 8, 5, 2, 7, 5, 4, 3, 8, 3, 8, 16, 1, 11, 3, 23, 2, 7, 6, 3, 9, 8, 1, 21, 4, 8, 6, 1, 13, 16, 13, 1, 13, 15, 6, 3, 12, 4, 10, 1, 21, 4, 12, 5, 9, 7, 18, 20], [19, 9, 15, 16, 14, 5, 1, 23, 3, 11, 2, 9, 1, 22, 4, 10, 13, 4, 7, 5, 26, 6, 1, 60, 41, 1, 19, 3, 8, 20, 1, 5, 14, 3, 8, 25, 1, 9, 23, 2, 7, 31, 17, 4, 3, 11, 36, 36, 36, 1, 41, 43, 52, 39, 6, 24, 1, 19, 2, 10, 4, 1, 10, 15, 16, 9, 6, 3, 1, 13, 4, 11, 2, 1, 10, 9, 8, 16, 1, 6, 5, 7, 3, 8, 16, 1, 47, 7, 11, 31, 7, 4, 5, 2, 1, 13, 9, 23, 3, 2, 6, 1, 6, 13, 4, 10, 10, 1, 6, 5, 15, 11, 3, 9, 6, 1, 35, 3, 8, 1, 12, 4, 6, 2, 24, 1, 13, 9, 8, 9, 16, 7, 4, 13, 31, 31, 5, 14, 2, 1, 9, 8, 2, 6, 1, 13, 4, 11, 2, 1, 19, 9, 22, 7, 18, 1, 19, 9, 18, 6, 1, 21, 3, 10, 13, 6, 34, 20, 1, 22, 7, 2, 5, 12, 14, 2, 11, 8, 2, 6, 6, 1, 21, 3, 10, 13, 6, 1, 4, 17, 17, 7, 9, 4, 12, 14, 1, 10, 2, 23, 2, 10, 1, 4, 22, 21, 15, 10, 8, 2, 6, 6, 1, 10, 4, 6, 5, 1, 21, 3, 10, 13, 6, 1, 4, 12, 14, 3, 2, 23, 2, 11, 1, 35, 2, 11, 1, 22, 9, 9, 11, 1, 30, 12, 10, 4, 6, 6, 3, 12, 6, 30, 1, 19, 7, 3, 11, 2, 1, 13, 9, 8, 6, 5, 2, 7, 1, 17, 10, 4, 8, 1, 43, 1, 9, 15, 5, 2, 7, 1, 6, 17, 4, 12, 2, 34, 24, 1, 8, 9, 8, 2, 5, 14, 2, 10, 2, 6, 6, 1, 17, 9, 9, 7, 1, 21, 3, 10, 13, 6, 1, 4, 23, 9, 3, 11, 2, 11, 1, 11, 3, 2, 31, 14, 4, 7, 11, 1, 21, 4, 8, 6, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 1, 9, 10, 11, 1, 13, 9, 23, 3, 2, 1, 33, 15, 8, 25, 3, 2, 24, 1, 16, 4, 23, 2, 1, 5, 7, 18, 20, 1, 19, 2, 6, 3, 11, 2, 6, 24, 1, 10, 2, 6, 6, 2, 7, 1, 21, 3, 10, 13, 6, 1, 4, 12, 5, 15, 4, 10, 10, 18, 1, 17, 7, 2, 5, 5, 18, 1, 16, 9, 9, 11, 31, 31, 33, 15, 6, 5, 1, 9, 8, 2, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 10, 15, 16, 9, 6, 3, 1, 3, 6, 24, 1, 2, 10, 6, 2, 24, 1, 13, 4, 11, 1, 6, 12, 3, 2, 8, 5, 3, 6, 5, 1, 22, 4, 8, 5, 6, 1, 25, 2, 2, 17, 1, 7, 4, 5, 14, 2, 7, 1, 19, 3, 37, 4, 7, 7, 2, 1, 23, 3, 9, 10, 2, 8, 5, 1, 22, 3, 21, 2, 1, 4, 10, 3, 23, 2, 1, 6, 2, 7, 15, 13, 1, 12, 9, 8, 12, 9, 12, 5, 6, 1, 18, 9, 15, 8, 16, 1, 19, 7, 3, 11, 2, 6, 20, 1, 8, 2, 23, 2, 7, 1, 7, 2, 4, 10, 10, 18, 1, 2, 32, 17, 10, 4, 3, 8, 2, 11, 1, 19, 7, 3, 11, 2, 6, 1, 13, 15, 6, 5, 1, 22, 9, 13, 2, 8, 1, 2, 23, 2, 8, 1, 11, 3, 6, 2, 4, 6, 2, 1, 22, 3, 21, 2, 1, 14, 4, 11, 31, 31, 6, 9, 1, 6, 2, 2, 1, 17, 10, 9, 5, 1, 8, 2, 23, 2, 7, 1, 7, 2, 4, 10, 10, 18, 1, 14, 4, 6, 14, 2, 11, 1, 4, 10, 10, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 4, 8, 18, 22, 4, 18, 6, 24, 1, 7, 2, 4, 10, 10, 18, 1, 4, 8, 8, 9, 18, 3, 8, 16, 1, 21, 2, 13, 4, 10, 2, 1, 7, 2, 17, 9, 7, 5, 2, 7, 1, 35, 4, 1, 10, 9, 3, 6, 1, 10, 4, 8, 2, 1, 5, 18, 17, 2, 1, 22, 3, 5, 14, 9, 15, 5, 1, 33, 3, 13, 13, 18, 1, 9, 10, 6, 2, 8, 1, 6, 15, 17, 2, 7, 13, 4, 8, 34, 1, 22, 4, 8, 5, 6, 1, 16, 2, 5, 1, 19, 9, 5, 5, 9, 13, 1, 4, 17, 17, 4, 7, 2, 8, 5, 1, 13, 15, 7, 11, 2, 7, 6, 1, 19, 9, 11, 3, 2, 6, 1, 6, 5, 9, 10, 2, 8, 36, 1, 6, 9, 24, 1, 21, 9, 10, 10, 9, 22, 6, 1, 12, 10, 15, 2, 6, 1, 22, 4, 18, 1, 11, 9, 9, 7, 6, 5, 2, 17, 1, 10, 15, 16, 9, 6, 3, 20, 1, 10, 15, 16, 9, 6, 3, 26, 6, 1, 14, 9, 13, 2, 1, 12, 9, 13, 17, 10, 2, 5, 2, 1, 12, 7, 4, 37, 2, 11, 1, 22, 3, 21, 2, 24, 1, 21, 2, 13, 4, 10, 2, 1, 4, 6, 6, 3, 6, 5, 4, 8, 5, 1, 5, 22, 9, 1, 6, 5, 7, 4, 8, 16, 2, 1, 17, 2, 9, 17, 10, 2, 1, 4, 17, 17, 4, 7, 2, 8, 5, 10, 18, 1, 4, 6, 6, 3, 6, 5, 4, 8, 5, 26, 6, 1, 6, 9, 8, 6, 1, 35, 4, 8, 1, 15, 16, 10, 18, 1, 14, 15, 8, 12, 14, 19, 4, 12, 25, 2, 11, 1, 6, 2, 32, 1, 21, 3, 2, 8, 11, 1, 11, 22, 4, 7, 21, 34, 20, 1, 8, 4, 5, 15, 7, 4, 10, 10, 18, 1, 17, 10, 15, 12, 25, 18, 1, 7, 2, 17, 9, 7, 5, 2, 7, 1, 21, 4, 3, 8, 5, 6, 1, 7, 2, 17, 2, 4, 5, 2, 11, 10, 18, 1, 5, 14, 7, 9, 15, 16, 14, 9, 15, 5, 1, 21, 3, 10, 13, 31, 31, 4, 17, 17, 4, 7, 2, 8, 5, 10, 18, 1, 8, 4, 7, 12, 9, 10, 2, 17, 6, 18, 1, 16, 9, 9, 11, 1, 3, 8, 23, 2, 6, 5, 3, 16, 4, 5, 3, 23, 2, 1, 33, 9, 15, 7, 8, 4, 10, 3, 6, 13, 1, 16, 9, 1, 14, 4, 8, 11, 1, 14, 4, 8, 11, 36, 1, 2, 23, 2, 8, 5, 15, 4, 10, 10, 18, 24, 1, 13, 4, 8, 3, 4, 12, 6, 1, 11, 3, 2, 31, 31, 13, 9, 6, 5, 10, 18, 1, 11, 15, 2, 1, 14, 4, 8, 11, 6, 1, 22, 2, 10, 10, 20, 1, 12, 9, 8, 12, 10, 15, 6, 3, 9, 8, 24, 1, 7, 2, 17, 9, 7, 5, 2, 7, 1, 11, 9, 12, 5, 9, 7, 1, 13, 2, 5, 1, 11, 2, 12, 3, 11, 2, 1, 13, 4, 7, 7, 18, 20, 1, 4, 8, 11, 24, 1, 8, 4, 5, 15, 7, 4, 10, 10, 18, 24, 1, 7, 2, 17, 9, 7, 5, 2, 7, 26, 6, 1, 11, 15, 13, 19, 1, 12, 4, 13, 2, 7, 4, 13, 4, 8, 1, 21, 4, 3, 8, 5, 6, 1, 9, 12, 12, 15, 7, 6, 20, 1, 14, 4, 23, 2, 8, 26, 5, 1, 8, 9, 5, 3, 12, 2, 11, 24, 1, 5, 14, 2, 7, 2, 26, 6, 1, 10, 9, 5, 1, 21, 4, 3, 8, 5, 3, 8, 16, 1, 21, 3, 10, 13, 20, 1, 9, 7, 24, 1, 13, 4, 18, 19, 2, 1, 6, 10, 9, 22, 1, 17, 9, 8, 11, 2, 7, 9, 15, 6, 1, 21, 3, 10, 13, 1, 21, 2, 10, 10, 1, 4, 6, 10, 2, 2, 17, 36], [12, 4, 13, 2, 1, 7, 2, 23, 3, 2, 22, 1, 10, 4, 6, 5, 1, 8, 3, 16, 14, 5, 1, 11, 2, 12, 3, 11, 3, 8, 16, 1, 5, 23, 1, 13, 9, 23, 3, 2, 1, 6, 2, 5, 5, 10, 2, 1, 21, 7, 9, 8, 5, 1, 9, 21, 24, 1, 21, 9, 15, 8, 11, 1, 13, 4, 11, 2, 1, 9, 8, 2, 1, 10, 9, 9, 25, 1, 15, 8, 13, 3, 6, 6, 4, 19, 10, 2, 20, 1, 13, 3, 6, 10, 2, 11, 1, 21, 2, 2, 10, 36, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 21, 3, 7, 6, 5, 10, 18, 24, 1, 8, 2, 2, 11, 6, 1, 17, 9, 3, 8, 5, 2, 11, 1, 21, 7, 9, 8, 5, 1, 13, 15, 12, 14, 1, 14, 9, 15, 6, 2, 22, 3, 21, 2, 26, 6, 1, 11, 4, 18, 5, 3, 13, 2, 1, 13, 9, 23, 3, 2, 20, 1, 17, 2, 7, 21, 9, 7, 13, 4, 8, 12, 2, 6, 1, 22, 9, 9, 11, 2, 8, 24, 1, 2, 23, 2, 7, 18, 1, 6, 2, 8, 5, 2, 8, 12, 2, 1, 4, 5, 5, 2, 13, 17, 5, 1, 26, 17, 9, 3, 16, 8, 4, 8, 5, 26, 1, 22, 4, 18, 1, 14, 9, 15, 6, 2, 22, 3, 21, 2, 26, 6, 1, 11, 4, 18, 5, 3, 13, 2, 1, 13, 9, 23, 3, 2, 6, 1, 19, 4, 11, 1, 6, 9, 4, 17, 1, 9, 17, 2, 7, 4, 6, 1, 4, 10, 22, 4, 18, 6, 1, 4, 7, 2, 24, 1, 19, 4, 6, 2, 11, 1, 17, 7, 2, 11, 3, 12, 5, 4, 19, 10, 2, 1, 22, 2, 10, 10, 31, 5, 7, 9, 11, 11, 2, 8, 1, 17, 7, 2, 13, 3, 6, 2, 1, 13, 2, 8, 1, 35, 17, 4, 7, 5, 3, 12, 15, 10, 4, 7, 10, 18, 1, 6, 9, 10, 11, 3, 2, 7, 6, 34, 1, 2, 6, 6, 2, 8, 5, 3, 4, 10, 10, 18, 1, 23, 3, 9, 10, 2, 8, 5, 1, 3, 8, 12, 9, 13, 17, 4, 6, 6, 3, 9, 8, 4, 5, 2, 20, 1, 22, 14, 9, 10, 2, 1, 13, 9, 23, 3, 2, 1, 26, 11, 7, 4, 13, 4, 26, 1, 4, 17, 17, 4, 7, 2, 8, 5, 1, 13, 9, 13, 2, 8, 5, 6, 1, 13, 4, 10, 2, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 6, 1, 5, 14, 7, 2, 4, 5, 2, 8, 1, 11, 2, 23, 2, 10, 9, 17, 1, 6, 2, 12, 9, 8, 11, 1, 11, 3, 13, 2, 8, 6, 3, 9, 8, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 21, 1, 6, 9, 15, 8, 11, 6, 1, 5, 9, 10, 2, 7, 4, 19, 10, 2, 1, 35, 9, 7, 1, 2, 23, 2, 8, 1, 2, 8, 33, 9, 18, 4, 19, 10, 2, 34, 1, 18, 9, 15, 24, 1, 22, 4, 7, 8, 2, 11, 20, 1, 10, 3, 8, 11, 4, 1, 14, 4, 13, 3, 10, 5, 9, 8, 26, 6, 1, 16, 2, 7, 13, 4, 8, 1, 4, 12, 12, 2, 8, 5, 24, 1, 38, 15, 3, 5, 2, 1, 16, 9, 9, 11, 24, 1, 17, 4, 3, 8, 21, 15, 10, 10, 18, 1, 11, 3, 6, 5, 7, 4, 12, 5, 3, 8, 16, 1, 31, 1, 21, 4, 12, 2, 24, 1, 7, 2, 4, 6, 9, 8, 20, 1, 17, 2, 7, 21, 9, 7, 13, 4, 8, 12, 2, 6, 1, 11, 9, 15, 19, 5, 1, 2, 8, 11, 15, 7, 3, 8, 16, 1, 6, 9, 15, 7, 12, 2, 1, 2, 13, 19, 4, 7, 7, 4, 6, 6, 13, 2, 8, 5, 1, 17, 2, 7, 17, 2, 5, 7, 4, 5, 9, 7, 6, 24, 1, 17, 4, 3, 8, 21, 15, 10, 10, 18, 1, 5, 14, 3, 8, 1, 9, 19, 23, 3, 9, 15, 6, 1, 12, 14, 4, 7, 4, 12, 5, 2, 7, 3, 37, 4, 5, 3, 9, 8, 6, 1, 9, 7, 11, 2, 7, 1, 11, 4, 18, 20, 1, 6, 15, 7, 17, 7, 3, 6, 2, 6, 24, 1, 22, 4, 5, 12, 14, 1, 26, 13, 9, 8, 5, 18, 1, 17, 18, 5, 14, 9, 8, 2, 6, 38, 15, 2, 26, 1, 2, 8, 11, 10, 2, 6, 6, 1, 6, 15, 17, 17, 10, 18, 1, 21, 9, 9, 11, 1, 11, 7, 3, 8, 25, 1, 13, 3, 7, 4, 12, 15, 10, 9, 15, 6, 10, 18, 1, 4, 17, 17, 2, 4, 7, 6, 1, 14, 15, 8, 16, 7, 18, 1, 6, 9, 10, 11, 3, 2, 7, 6, 26, 1, 25, 8, 4, 17, 6, 4, 12, 25, 6, 36, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 3, 1, 22, 4, 6, 8, 26, 5, 1, 2, 32, 17, 2, 12, 5, 3, 8, 16, 1, 4, 12, 5, 3, 9, 8, 24, 1, 14, 9, 17, 2, 11, 1, 19, 2, 4, 15, 5, 3, 21, 15, 10, 1, 5, 2, 32, 5, 15, 7, 4, 10, 1, 2, 13, 9, 5, 3, 9, 8, 4, 10, 10, 18, 1, 12, 14, 4, 7, 16, 2, 11, 20, 1, 16, 9, 5, 1, 17, 4, 7, 5, 3, 12, 15, 10, 4, 7, 10, 18, 1, 19, 4, 11, 1, 12, 14, 7, 3, 6, 5, 13, 4, 6, 1, 26, 21, 2, 2, 10, 16, 9, 9, 11, 26, 1, 6, 5, 9, 7, 18, 1, 3, 8, 5, 2, 10, 10, 3, 16, 2, 8, 5, 1, 4, 15, 11, 3, 2, 8, 12, 2, 1, 12, 7, 3, 8, 16, 3, 8, 16, 1, 12, 7, 4, 17, 15, 10, 2, 8, 12, 2, 1, 4, 10, 10, 20, 29, 19, 7, 1, 27, 28, 29, 19, 7, 1, 27, 28, 22, 4, 5, 12, 14, 1, 21, 9, 10, 9, 22, 3, 8, 16, 1, 12, 3, 7, 12, 15, 13, 6, 5, 4, 8, 12, 2, 6, 42, 1, 41, 42, 1, 5, 14, 2, 7, 2, 26, 6, 1, 8, 9, 5, 14, 3, 8, 16, 1, 2, 10, 6, 2, 1, 9, 8, 20, 1, 44, 42, 1, 21, 4, 8, 1, 17, 7, 2, 11, 3, 12, 5, 4, 19, 10, 2, 1, 26, 14, 9, 15, 6, 2, 22, 3, 21, 2, 1, 5, 4, 25, 2, 6, 1, 13, 2, 8, 1, 22, 3, 8, 6, 26, 1, 5, 23, 1, 13, 9, 23, 3, 2, 6, 20, 1, 47, 42, 1, 22, 4, 18, 1, 4, 17, 17, 7, 2, 12, 3, 4, 5, 2, 1, 5, 7, 15, 2, 1, 6, 5, 9, 7, 18, 1, 14, 9, 10, 10, 18, 22, 9, 9, 11, 1, 5, 15, 7, 8, 6, 1, 21, 2, 4, 5, 15, 7, 2, 1, 21, 3, 10, 13, 20, 1, 52, 42, 1, 18, 9, 15, 26, 23, 2, 1, 3, 13, 19, 3, 19, 2, 11, 1, 2, 8, 9, 15, 16, 14, 1, 8, 9, 16, 1, 2, 13, 9, 5, 3, 9, 8, 6, 1, 2, 4, 6, 3, 10, 18, 1, 6, 5, 3, 7, 7, 2, 11, 1, 15, 8, 6, 9, 17, 14, 3, 6, 5, 3, 12, 4, 5, 2, 11, 1, 6, 5, 9, 7, 18, 5, 2, 10, 10, 3, 8, 16, 20]]\n",
            "Vocabulary Size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create TF Datasets**\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : TF Data</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>"
      ],
      "metadata": {
        "id": "URNynC6EZbuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_shuffle_buffer_size = len(train_token_x)\n",
        "validation_shuffle_buffer_size = len(validate_token_x)\n",
        "\n",
        "def pad(x, y):\n",
        "  return x.to_tensor(default_value=0, shape=[None, None]), y\n",
        "\n",
        "# Use tensorflow ragged constants to get the ragged version of data\n",
        "train_processed_x = tf.ragged.constant(train_token_x)\n",
        "validate_processed_x = tf.ragged.constant(validate_token_x)\n",
        "train_processed_y = tf.ragged.constant(train_y)\n",
        "validate_processed_y = tf.ragged.constant(validate_y)\n",
        "\n",
        "# Create TF Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_processed_x, train_processed_y))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((validate_processed_x, validate_processed_y))\n",
        "\n",
        "#############\n",
        "# Train data\n",
        "#############\n",
        "# Apply all data processing logic\n",
        "train_data = train_data.shuffle(buffer_size=train_shuffle_buffer_size)\n",
        "train_data = train_data.batch(batch_size)\n",
        "train_data = train_data.map(pad, num_parallel_calls=AUTOTUNE)\n",
        "train_data = train_data.prefetch(AUTOTUNE)\n",
        "#train_data = train_data.cache()\n",
        "\n",
        "##################\n",
        "# Validation data\n",
        "##################\n",
        "# Apply all data processing logic\n",
        "#validation_data = validation_data.shuffle(buffer_size=validation_shuffle_buffer_size)\n",
        "validation_data = validation_data.batch(batch_size)\n",
        "validation_data = validation_data.map(pad, num_parallel_calls=AUTOTUNE)\n",
        "validation_data = validation_data.prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"train_data\",train_data)\n",
        "print(\"validation_data\",validation_data)"
      ],
      "metadata": {
        "id": "cWmonsdsZbuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11d99fd-58b6-4468-934c-d7e0b49edf3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data <PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n",
            "validation_data <PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View some data from tf dataset\n",
        "for input,output in train_data.take(1):\n",
        "  print(input.shape,output.shape)\n",
        "  \n",
        "  print(\"Input:\",input[0])\n",
        "  print(\"Output:\",output[0])\n",
        "  print(\"****************\")\n",
        "  print(\"Input:\",input[1])\n",
        "  print(\"Output:\",output[1])"
      ],
      "metadata": {
        "id": "j0H8WLCVZbuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94e5334-aae3-4094-c909-a22142067605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 3405) (64,)\n",
            "Input: tf.Tensor([ 6  4 22 ...  0  0  0], shape=(3405,), dtype=int32)\n",
            "Output: tf.Tensor(0, shape=(), dtype=int64)\n",
            "****************\n",
            "Input: tf.Tensor([33  4  8 ...  0  0  0], shape=(3405,), dtype=int32)\n",
            "Output: tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Model**\n",
        "\n",
        "Now define a simple single layer LSTM model"
      ],
      "metadata": {
        "id": "99O9ogs3Zbuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate = 1e-2\n",
        "epochs = 20\n",
        "embedding_dim = 128\n",
        "hidden_size = 12"
      ],
      "metadata": {
        "id": "OIKFBLjF2txF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : Model using functional API</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>"
      ],
      "metadata": {
        "id": "XXkmM9fjZbug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_simple_lstm_model(num_classes,vocab_size,embedding_dim,hidden_size):\n",
        "  # Model input\n",
        "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
        "\n",
        "  # Embedding\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
        "                        name='word_embedding', mask_zero=True)(model_input)\n",
        "\n",
        "  # LSTM layer\n",
        "  hidden1 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=False)(embedding)\n",
        "\n",
        "  hidden = tf.keras.layers.Dense(units=hidden_size, activation='relu')(hidden1)\n",
        "\n",
        "  # Output Layer\n",
        "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(hidden)\n",
        "\n",
        "  # Create model\n",
        "  model = tf.keras.Model(inputs=model_input, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4INnX-cLZbug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "A6Zv837UZbug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Free up memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model = build_simple_lstm_model(num_classes,vocabulary_size, embedding_dim, hidden_size)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Loss\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_data,\n",
        "        validation_data= validation_data,\n",
        "        epochs=epochs, \n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "3m5vEz19Zbug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75bc957-f9f5-4201-8fa0-43bc3c98e408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sentence_input (InputLayer)  [(None, None)]           0         \n",
            "                                                                 \n",
            " word_embedding (Embedding)  (None, None, 128)         1280128   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 12)                6768      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                156       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,287,078\n",
            "Trainable params: 1,287,078\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "125/125 [==============================] - 21s 129ms/step - loss: 0.6809 - accuracy: 0.5353 - val_loss: 0.6834 - val_accuracy: 0.5215\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.6593 - accuracy: 0.5609 - val_loss: 0.6631 - val_accuracy: 0.5510\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 15s 119ms/step - loss: 0.6505 - accuracy: 0.5675 - val_loss: 0.6690 - val_accuracy: 0.5650\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.6462 - accuracy: 0.5659 - val_loss: 0.6652 - val_accuracy: 0.5565\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.6412 - accuracy: 0.5769 - val_loss: 0.6613 - val_accuracy: 0.5590\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 0.6400 - accuracy: 0.5716 - val_loss: 0.6578 - val_accuracy: 0.5590\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 0.6362 - accuracy: 0.5739 - val_loss: 0.6588 - val_accuracy: 0.5585\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 0.6303 - accuracy: 0.5907 - val_loss: 0.6732 - val_accuracy: 0.5330\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 15s 123ms/step - loss: 0.6307 - accuracy: 0.5824 - val_loss: 0.6624 - val_accuracy: 0.5650\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 16s 128ms/step - loss: 0.6251 - accuracy: 0.5920 - val_loss: 0.6538 - val_accuracy: 0.5660\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6234 - accuracy: 0.5943 - val_loss: 0.6630 - val_accuracy: 0.5705\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 0.6199 - accuracy: 0.6022 - val_loss: 0.6636 - val_accuracy: 0.5740\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6214 - accuracy: 0.5962 - val_loss: 0.6744 - val_accuracy: 0.5615\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6212 - accuracy: 0.5999 - val_loss: 0.6590 - val_accuracy: 0.5645\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6229 - accuracy: 0.6019 - val_loss: 0.6649 - val_accuracy: 0.5560\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6232 - accuracy: 0.5990 - val_loss: 0.6894 - val_accuracy: 0.5625\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6232 - accuracy: 0.6015 - val_loss: 0.6529 - val_accuracy: 0.5670\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 15s 120ms/step - loss: 0.6195 - accuracy: 0.6044 - val_loss: 0.6721 - val_accuracy: 0.5660\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6190 - accuracy: 0.6053 - val_loss: 0.6587 - val_accuracy: 0.5560\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 15s 121ms/step - loss: 0.6194 - accuracy: 0.6068 - val_loss: 0.6534 - val_accuracy: 0.5705\n",
            "Training execution time (mins) 5.15596330165863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training results\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "axs = fig.add_subplot(1,3,1)\n",
        "axs.set_title('Loss')\n",
        "# Plot all metrics\n",
        "for metric in [\"loss\",\"val_loss\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "axs = fig.add_subplot(1,3,2)\n",
        "axs.set_title('Accuracy')\n",
        "# Plot all metrics\n",
        "for metric in [\"accuracy\",\"val_accuracy\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bmb4iZw2Zbug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1cd02c09-fc0e-4786-a3c7-6b22158c1d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate**"
      ],
      "metadata": {
        "id": "jQrS5LzYHWZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "pred = model.predict(validation_data)\n",
        "pred = pred.argmax(axis=1)\n",
        "\n",
        "# Print the classification report comparing the true labels and the predicted ones\n",
        "print(classification_report(validate_processed_y, pred))"
      ],
      "metadata": {
        "id": "FVBEjfDa3hKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dce1d8-7122-471a-8139-e557822bc05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.48      0.53      1002\n",
            "           1       0.56      0.66      0.61       998\n",
            "\n",
            "    accuracy                           0.57      2000\n",
            "   macro avg       0.57      0.57      0.57      2000\n",
            "weighted avg       0.57      0.57      0.57      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model with Residual Connections üéäüéâ**\n",
        "\n",
        "Now define LSTM model with residual connections. \n",
        "\n",
        "From the google [Translate paper](https://arxiv.org/abs/1609.08144), we can see that skip connections enable us to train deeper recurrent networks.\n",
        "\n",
        "For that, add skips connections between different LSTMs layers."
      ],
      "metadata": {
        "id": "4yF484jL3Vvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : Model using functional API</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>\n",
        "\n",
        "**<font color='red'>Activity</font> üéäüéâ** "
      ],
      "metadata": {
        "id": "t0NK8H9FIk6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_residual_connections_model(num_classes,vocab_size,embedding_dim,hidden_size):\n",
        "  # Model input\n",
        "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
        "\n",
        "  # Embedding\n",
        "  # Add a embedding layer with dimension tokenizer.num_words+1 and embedding size.\n",
        "  # Set mask_zero as true \n",
        "  embedding = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
        "                        name='word_embedding', mask_zero=True)(model_input)\n",
        "\n",
        "  # Add an LSTM layer with hidden size and return the sequences\n",
        "  hidden1 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(embedding)\n",
        "  # Create residual connection\n",
        "  #residual1 = hidden1 + embedding # This will not work the dimension of embedding cannot be added to hidden1\n",
        "  embedding_projections = tf.keras.layers.Dense(units=hidden_size, activation='relu')\n",
        "  residual1 = hidden1 + embedding_projections(embedding)\n",
        "\n",
        "  # Add another LSTM layer with hidden size and return the sequences\n",
        "  hidden2 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual1)\n",
        "  # Create a residual connection\n",
        "  residual2 = hidden2 + hidden1\n",
        "\n",
        "  # Add another LSTM layer with hidden size and return the sequences\n",
        "  hidden3 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual2)\n",
        "  # Create a residual connection\n",
        "  residual3 = hidden3 + hidden2\n",
        "\n",
        "  # Add another LSTM layer with hidden size and return the sequences\n",
        "  hidden4 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual3)\n",
        "\n",
        "  # Concatenate all hidden states\n",
        "  hidden = tf.keras.layers.Concatenate(axis=2)([hidden1, hidden2, hidden3, hidden4])\n",
        "\n",
        "  # Use last LSTM layer with hidden size and return sequences False\n",
        "  final = tf.keras.layers.LSTM(units=hidden_size, return_sequences=False)(hidden)\n",
        "\n",
        "  # Output Layer\n",
        "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(final)\n",
        "\n",
        "  # Create model\n",
        "  model = tf.keras.Model(inputs=model_input, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Iu8v9b9C3ang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**"
      ],
      "metadata": {
        "id": "RMRnWmie-SWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_solution(\"https://storage.googleapis.com/public-code-snippets/cs109b_lab9_activity2.txt\")"
      ],
      "metadata": {
        "id": "UQpOnFN8EIq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59712b1b-b95e-46a6-9d94-8cf46cac1d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def build_lstm_residual_connections_model(num_classes,vocab_size,embedding_dim,hidden_size):\n",
            "  # Model input\n",
            "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
            "\n",
            "  # Embedding\n",
            "  # Add a embedding layer with dimension tokenizer.num_words+1 and embedding size.\n",
            "  # Set mask_zero as true \n",
            "  embedding = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
            "                        name='word_embedding', mask_zero=True)(model_input)\n",
            "\n",
            "  # Add an LSTM layer with hidden size and return the sequences\n",
            "  hidden1 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(embedding)\n",
            "  # Create residual connection\n",
            "  #residual1 = hidden1 + embedding # This will not work the dimension of embedding cannot be added to hidden1\n",
            "  embedding_projections = tf.keras.layers.Dense(units=hidden_size, activation='relu')\n",
            "  residual1 = hidden1 + embedding_projections(embedding)\n",
            "\n",
            "  # Add another LSTM layer with hidden size and return the sequences\n",
            "  hidden2 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual1)\n",
            "  # Create a residual connection\n",
            "  residual2 = hidden2 + hidden1\n",
            "\n",
            "  # Add another LSTM layer with hidden size and return the sequences\n",
            "  hidden3 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual2)\n",
            "  # Create a residual connection\n",
            "  residual3 = hidden3 + hidden2\n",
            "\n",
            "  # Add another LSTM layer with hidden size and return the sequences\n",
            "  hidden4 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True)(residual3)\n",
            "\n",
            "  # Concatenate all hidden states\n",
            "  hidden = tf.keras.layers.Concatenate(axis=2)([hidden1, hidden2, hidden3, hidden4])\n",
            "\n",
            "  # Use last LSTM layer with hidden size and return sequences False\n",
            "  final = tf.keras.layers.LSTM(units=hidden_size, return_sequences=False)(hidden)\n",
            "\n",
            "  # Output Layer\n",
            "  output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(final)\n",
            "\n",
            "  # Create model\n",
            "  model = tf.keras.Model(inputs=model_input, outputs=output)\n",
            "\n",
            "  return model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "_aRiLZ46Hbft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate = 1e-2\n",
        "epochs = 3 # 20\n",
        "embedding_dim = 128\n",
        "hidden_size = 12\n",
        "\n",
        "# Free up memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model = build_lstm_residual_connections_model(num_classes,vocabulary_size, embedding_dim, hidden_size)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Loss\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_data,\n",
        "        validation_data= validation_data,\n",
        "        epochs=epochs, \n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "OneJ3WIW39nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144cc602-65ff-48f0-9256-bcc07a77ab70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " sentence_input (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " word_embedding (Embedding)     (None, None, 128)    1280128     ['sentence_input[0][0]']         \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, None, 12)     6768        ['word_embedding[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 12)     1548        ['word_embedding[0][0]']         \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, None, 12)    0           ['lstm[0][0]',                   \n",
            " da)                                                              'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, None, 12)     1200        ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, None, 12)    0           ['lstm_1[0][0]',                 \n",
            " mbda)                                                            'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, None, 12)     1200        ['tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, None, 12)    0           ['lstm_2[0][0]',                 \n",
            " mbda)                                                            'lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, None, 12)     1200        ['tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, 48)     0           ['lstm[0][0]',                   \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'lstm_2[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 12)           2928        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            26          ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,294,998\n",
            "Trainable params: 1,294,998\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "125/125 [==============================] - 86s 606ms/step - loss: 0.6837 - accuracy: 0.5286 - val_loss: 0.6733 - val_accuracy: 0.5465\n",
            "Epoch 2/3\n",
            "125/125 [==============================] - 71s 571ms/step - loss: 0.6614 - accuracy: 0.5601 - val_loss: 0.6625 - val_accuracy: 0.5500\n",
            "Epoch 3/3\n",
            "125/125 [==============================] - 71s 572ms/step - loss: 0.6556 - accuracy: 0.5636 - val_loss: 0.6589 - val_accuracy: 0.5575\n",
            "Training execution time (mins) 3.810488470395406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training results\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "axs = fig.add_subplot(1,3,1)\n",
        "axs.set_title('Loss')\n",
        "# Plot all metrics\n",
        "for metric in [\"loss\",\"val_loss\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "axs = fig.add_subplot(1,3,2)\n",
        "axs.set_title('Accuracy')\n",
        "# Plot all metrics\n",
        "for metric in [\"accuracy\",\"val_accuracy\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MoGs1bSP4DiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate**"
      ],
      "metadata": {
        "id": "BIPA7_lmHNib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "pred = model.predict(validation_data)\n",
        "pred = pred.argmax(axis=1)\n",
        "\n",
        "# Print the classification report comparing the true labels and the predicted ones\n",
        "print(classification_report(validate_processed_y, pred))"
      ],
      "metadata": {
        "id": "dohbKwVT4D-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ELMo and Highway Networks**"
      ],
      "metadata": {
        "id": "qlSFbedknhnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps:**\n",
        "\n",
        "* Load the IMDB dataset from keras datasets\n",
        "* Split the dataset into train and test data and labels\n",
        "* Define the input and output of the ELMo model\n",
        "* Generate TF Datasets \n",
        "* Define a class HighwayLayer that inherits from tf.keras.layers.Layer to implement the highway network layer\n",
        "* Define an ELMo model with the custom highway layer\n",
        "* Compile and train the ELMo model\n",
        "* Plot the trace plot of the model history\n",
        "* For a sentence in the test dataset, extract both the word embeddings and the contextual embeddings of the sentence by passing it through the trained ELMo model"
      ],
      "metadata": {
        "id": "oKmcEiWGq0rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the data**\n",
        "\n",
        "\n",
        "Load the IMDB dataset"
      ],
      "metadata": {
        "id": "HkYc9GyB5SVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the helper code given to load the IMDB dataset with the following parameters\n",
        "n_words = 2000\n",
        "skip= 100\n",
        "data_train, data_validation = tf.keras.datasets.imdb.load_data(num_words=n_words,skip_top=skip, maxlen=200 )"
      ],
      "metadata": {
        "id": "p3T73Ff8q2Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"data_train input shape:\",data_train[0].shape)\n",
        "print(\"data_train output shape:\",data_train[1].shape)\n",
        "print(\"data_validation input shape:\",data_validation[0].shape)\n",
        "print(\"data_validation outout shape:\",data_validation[1].shape)\n",
        "\n",
        "# View a training samples\n",
        "for i in range(5):\n",
        "  print(\"Length:\",len(data_train[0][i]))\n",
        "  print(data_train[0][i])\n",
        "  print(data_train[1][i])"
      ],
      "metadata": {
        "id": "xzJyuA-EvRCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our input sentences are ragged and we will need to handle that in our data pipeleines to feed to the model for training"
      ],
      "metadata": {
        "id": "pCB9mxVewed7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Helper code to fix the mapping of the imdb word index\n",
        "index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# we need to add 3 from the indices because 0 is 'padding', 1 is 'start of sequence' and 2 is 'unknown'\n",
        "inv_index = { j+3:i for i,j in index.items()}\n",
        "inv_index[0] = \"\"\n",
        "inv_index[1] = \"<s>\"\n",
        "inv_index[2] = \"UNK\""
      ],
      "metadata": {
        "id": "YggN3MpJseJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display actual text\n",
        "review = [inv_index[token] for token in data_train[0][0]]\n",
        "print(\"review:\",\" \".join(review))"
      ],
      "metadata": {
        "id": "J9AsfvP_svoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build Data Pipelines**"
      ],
      "metadata": {
        "id": "cEdWtmmKH4IK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The data is already preprocessed. \n",
        "* We define the input and target words.\n",
        "\n",
        "* We will predict the next word based on the input."
      ],
      "metadata": {
        "id": "nryyOObluLCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Generate Training Data**\n",
        "\n",
        "For the training the model we need sentences as inputs and outputs. We will train the models in a semi-supervised way. So the input will be all the words of the sentence, except the last one. The output is all the words of the sentence, except the first one"
      ],
      "metadata": {
        "id": "iexkI1sgucD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input and output of the network for both, the train and test sets\n",
        "# The input is the all the words of the sentence, except the last one\n",
        "# The output is all the words of the sentence, except the first one\n",
        "\n",
        "train_x  = [i[:-1] for i in data_train[0]]\n",
        "train_y = [i[1:] for i in data_train[0]]\n",
        "\n",
        "validation_x  = [i[:-1] for i in data_validation[0]]\n",
        "validation_y = [i[1:] for i in data_validation[0]]"
      ],
      "metadata": {
        "id": "bjqGwoVbu5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a few samples\n",
        "for i in range(5):\n",
        "  print(\"\")\n",
        "  print(\"Length:\",len(train_x[i]),train_x[i])\n",
        "  print(\"Length:\",len(train_y[i]),train_y[i])"
      ],
      "metadata": {
        "id": "HABDo8ifujdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create TF Datasets**\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : TF Data</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>"
      ],
      "metadata": {
        "id": "FXJA4GpAH_0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "train_shuffle_buffer_size = len(train_x)\n",
        "validation_shuffle_buffer_size = len(validate_x)\n",
        "\n",
        "def pad(x, y):\n",
        "  return (x.to_tensor(default_value=0, shape=[None, None]), y.to_tensor(default_value=0, shape=[None, None]))\n",
        "\n",
        "# Use tensorflow ragged constants to get the ragged version of data\n",
        "train_processed_x = tf.ragged.constant(train_x)\n",
        "validation_processed_x = tf.ragged.constant(validation_x)\n",
        "train_processed_y = tf.ragged.constant(train_y)\n",
        "validation_processed_y = tf.ragged.constant(validation_y)\n",
        "\n",
        "# Create TF Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_processed_x, train_processed_y))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((validation_processed_x, validation_processed_y))\n",
        "\n",
        "#############\n",
        "# Train data\n",
        "#############\n",
        "# Apply all data processing logic\n",
        "train_data = train_data.shuffle(buffer_size=train_shuffle_buffer_size)\n",
        "train_data = train_data.batch(batch_size)\n",
        "train_data = train_data.map(pad, num_parallel_calls=AUTOTUNE)\n",
        "train_data = train_data.prefetch(AUTOTUNE)\n",
        "\n",
        "##################\n",
        "# Validation data\n",
        "##################\n",
        "# Apply all data processing logic\n",
        "validation_data = validation_data.shuffle(buffer_size=validation_shuffle_buffer_size)\n",
        "validation_data = validation_data.batch(batch_size)\n",
        "validation_data = validation_data.map(pad, num_parallel_calls=AUTOTUNE)\n",
        "validation_data = validation_data.prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"train_data\",train_data)\n",
        "print(\"validation_data\",validation_data)"
      ],
      "metadata": {
        "id": "D8AKabvwu5Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View some data from tf dataset\n",
        "for input,output in train_data.take(1):\n",
        "  print(input.shape,output.shape)\n",
        "  \n",
        "  print(\"Input:\",input[0])\n",
        "  print(\"Output:\",output[0])\n",
        "  # print(\"****************\")\n",
        "  # print(\"Input:\",input[1])\n",
        "  # print(\"Output:\",output[1])"
      ],
      "metadata": {
        "id": "iTsUEtbiu5QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ELMo Model üéäüéâ**\n",
        "\n",
        "Now Build the ELMo model to extract embeddings"
      ],
      "metadata": {
        "id": "h9J0amoF6f6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Highway Network Layer**\n",
        "\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : Custom Layer</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>"
      ],
      "metadata": {
        "id": "5okacC9tQGk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You should include a highway connection between the layers of the LSTM. Keras doesn't have it by default.\n",
        "\n",
        "Remember that a highway network is written as:\n",
        "$$x = z \\odot T +r \\odot C$$\n",
        "Where $r$ is the output of the previous layer, $z$ the result of a dense layer applied to $r$, $T$ and $C$ the Transform gate and Carry gate, respectively.\n",
        "\n",
        "For simplicity, we assume that $C$ = $1-T$. Then, the highway network is:\n",
        "\\begin{align}\n",
        "x &= z \\odot T +r \\odot (1-T) \\\\\n",
        "&= z \\odot T -r \\odot T+ r \\\\\n",
        "&= (z -r)\\odot T + r \n",
        "\\end{align}\n",
        "$$ $$\n",
        "To create a the highway network, we create the $T$ vector to multiplicate each value of the input.\n",
        "\n",
        "\n",
        "Note that we add self.supports_masking = True to support masking. This attribute ensures that the layer will propagate its input mask to its outputs; masking in Keras is by default False. \n",
        "\n",
        "**<font color='red'>Activity</font> üéäüéâ** "
      ],
      "metadata": {
        "id": "1h_0esZsy6ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class that builds the custom layer for the highway network\n",
        "# This will implement the equation presented above\n",
        "\n",
        "class HighwayLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "      super(HighwayLayer, self).__init__()\n",
        "      self.supports_masking = ___\n",
        "    \n",
        "    # The __call__() method of your layer will automatically run build the first time it is called\n",
        "    def build(self, input_shape):\n",
        "      # Create the state of the layer (weights)\n",
        "      # Define a tf.Variable using tf.random_normal_initializer with mean=0.0 and stddev=0.05, shape=[1,input_shape[-1]\n",
        "      # Make sure to set tge trainable=True for the tf.Variable\n",
        "      self.T = ___     \n",
        "\n",
        "    def call(self, z, r):\n",
        "      # compute the highway network output as show above\n",
        "      return ___\n"
      ],
      "metadata": {
        "id": "ZKRe1zPVzAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution**"
      ],
      "metadata": {
        "id": "pxV_vivI-lFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##display_solution(\"https://storage.googleapis.com/public-code-snippets/cs109b_lab9_activity3.txt\")"
      ],
      "metadata": {
        "id": "JgjgNbEUEOgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Model**\n",
        "\n",
        "<p>üõëüõëüõë &nbsp;&nbsp;<strong><font color=\"green\">üîë Keys to DNN Kingdom üëë : Model using functional API</font></strong>&nbsp;&nbsp;üõëüõëüõë</p>"
      ],
      "metadata": {
        "id": "bxQ8zsY1IesN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size,embedding_dim,hidden_size):\n",
        "  # Model input\n",
        "  model_input = tf.keras.Input(shape=(None,), name='sentence_input')\n",
        "\n",
        "  # Embedding\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dim, \n",
        "                        name='embedding', mask_zero=True)(model_input)\n",
        "\n",
        "  # LSTM layer\n",
        "  r = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True, name=\"r\")(embedding)\n",
        "  z = tf.keras.layers.Dense(units=hidden_size,name=\"z\")(r)\n",
        "\n",
        "  # Highway\n",
        "  h1_hw = HighwayLayer()(z,r)\n",
        "\n",
        "  h2 = tf.keras.layers.LSTM(units=hidden_size, return_sequences=True, name=\"h2\")(h1_hw)\n",
        "\n",
        "  # Output Layer\n",
        "  output = tf.keras.layers.Dense(units=vocab_size+1, activation='softmax', name='softmax_layer')(h2)\n",
        "\n",
        "  # Create model\n",
        "  model = tf.keras.Model(inputs=model_input, outputs=output)\n",
        "\n",
        "  # Create Toy ELMo model\n",
        "  toy_ELMo = tf.keras.Model(inputs=model_input, outputs=[embedding,h2], name='Toy_ELMo')\n",
        "\n",
        "  return model, toy_ELMo"
      ],
      "metadata": {
        "id": "Y469dIsB6sGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "kqG9wlHCHX_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate = 5e-2\n",
        "epochs = 10\n",
        "embedding_dim = 32\n",
        "hidden_size = 10\n",
        "vocabulary_size = n_words\n",
        "\n",
        "# Free up memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model, toy_ELMo = build_model(vocabulary_size, embedding_dim, hidden_size)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Loss\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_data,\n",
        "        validation_data= validation_data,\n",
        "        epochs=epochs, \n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "-srEwEZyK2X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Training Metrics"
      ],
      "metadata": {
        "id": "TRXolz0ez5_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training results\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "axs = fig.add_subplot(1,3,1)\n",
        "axs.set_title('Loss')\n",
        "# Plot all metrics\n",
        "for metric in [\"loss\",\"val_loss\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "axs = fig.add_subplot(1,3,2)\n",
        "axs.set_title('Accuracy')\n",
        "# Plot all metrics\n",
        "for metric in [\"accuracy\",\"val_accuracy\"]:\n",
        "    axs.plot(np.arange(0, epochs), training_results.history[metric], label=metric)\n",
        "axs.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RmyQL9pXLSg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract embedding of a sentence\n",
        "\n",
        "We can extract the word embeddings. For an arbitrary sentence, we extract the word embedding."
      ],
      "metadata": {
        "id": "1Vcp3rBB0ICe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View some data from tf dataset\n",
        "for batch in validation_data.take(1):\n",
        "  input, output = batch\n",
        "  print(input.shape,output.shape)"
      ],
      "metadata": {
        "id": "Vnd8lOUq0IcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the input through the toy elmo model\n",
        "model_outputs = toy_ELMo(input)\n",
        "print(\"model_outputs\",len(model_outputs))\n",
        "\n",
        "# Unpack the outputs\n",
        "embedding,h2 = model_outputs\n",
        "\n",
        "print(\"embedding:\",embedding.shape)\n",
        "print(embedding[0])\n",
        "print(\"h2:\",h2.shape)\n",
        "print(h2[0])"
      ],
      "metadata": {
        "id": "_lQDOOC3wOTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using TensorBoard in Colab**"
      ],
      "metadata": {
        "id": "WTagrYvswKBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the extension"
      ],
      "metadata": {
        "id": "Q2pP6SCKwQBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "idLq6bCzwRt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download some data"
      ],
      "metadata": {
        "id": "C08288NMwf8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_validation, y_validation) = fashion_mnist.load_data()\n",
        "x_train, x_validation = x_train / 255.0, x_validation / 255.0"
      ],
      "metadata": {
        "id": "j-XUGvqEwiJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creat a simple model"
      ],
      "metadata": {
        "id": "offKRi4Bwn3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])"
      ],
      "metadata": {
        "id": "U5RKTUmqwpyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start TensorBoard"
      ],
      "metadata": {
        "id": "0x74j9iCx-Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "_lagKQqXx-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using the Tensorboard checkpoint callback"
      ],
      "metadata": {
        "id": "mQ0nguizwsC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "learning_rate=0.001\n",
        "epochs = 10\n",
        "hidden_size = 10\n",
        "\n",
        "# Free up memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model = create_model()\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# Loss\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "# Compile\n",
        "model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "callbacks = [tensorboard_callback]\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        validation_data= (x_validation, y_validation),\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "metadata": {
        "id": "Rlfom8H4wrZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}